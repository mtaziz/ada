{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os #Needed to read all files in doc automatically\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Comentary:\n",
    "\n",
    "As all the csv files are structured in very different ways, I cleaned all data for each country individualy before merging it into one dataframe. <br/>\n",
    "**N.B.** : For clarity, we will only comment the code for the 3 data cleaning parts once for steps that are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = DATA_FOLDER + '/ebola/'\n",
    "\n",
    "#I procede to go through each folder, starting with Guinea\n",
    "\n",
    "guinea_frame = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path + 'guinea_data'):\n",
    "    frame = pd.read_csv(path + 'guinea_data/' + filename, parse_dates=['Date'],\n",
    "                        usecols = ['Date', 'Description', 'Totals']) #Keep only the 3 relevant colums\n",
    "    \n",
    "    #We are only interested in the New Deaths Registered or New Deaths Registered Today, the other lines are\n",
    "    #not relevant for our analysis\n",
    "    deaths = frame[['New deaths registered' in d for d in frame.Description]\n",
    "                  ][['Date', 'Totals']].drop_duplicates(subset='Date')\n",
    "    deaths.columns = ['Date', 'Deaths'] #Renaming for convenience\n",
    "        \n",
    "    \n",
    "    cases = frame[['Total new cases' in d for d in frame.Description]][['Date', 'Totals']]\n",
    "    cases.columns = ['Date', 'Cases'] #Renaming for convenience\n",
    "    \n",
    "    #Make sure that we get the same number of values per file (one row per date/csv file)\n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError \n",
    "    \n",
    "    total = pd.merge(deaths, cases, on='Date', how = 'inner')\n",
    "    total['Date'] = total['Date'].map(lambda x : x.month) #We only want to know about the month (all csv set in 2014)\n",
    "    guinea_frame = guinea_frame.append(total) #Aggregate all csv files\n",
    "\n",
    "guinea_frame['Country'] = 'Guinea'\n",
    "\n",
    "#Make sure we get some data from every document & we don't miss rows\n",
    "print('Getting all rows : ',\n",
    "      guinea_frame.Deaths.shape[0] == len(os.listdir(path + 'guinea_data')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part treats the data from Liberia. Overall, the transcription contains a lot of inconsistencies,\n",
    "which were adressed by treating cases seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "liberia_frame = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path + 'liberia_data'):\n",
    "    frame = pd.read_csv(path + 'liberia_data/' + filename, parse_dates=['Date'],\n",
    "                       usecols=['Date', 'Variable', 'National']) #Get only the 3 relevant colums\n",
    "    \n",
    "    #There is a csv containing duplicates on the variable columns\n",
    "    #As the values differ, I assumed that the first value is the correct one\n",
    "    frame = frame.drop_duplicates(subset='Variable') \n",
    "    \n",
    "    deaths = frame[[d in 'Newly reported deaths' for d in frame.Variable]][['Date', 'National']]\n",
    "    deaths.columns = ['Date', 'Deaths']\n",
    "    \n",
    "    #We get all 3 values of new cases (suspected, probable and confirmed) & sum them up\n",
    "    cases_int = frame[['New Case/s'.lower() in d.lower() for d in frame.Variable]][['Date', 'National']]  \n",
    "    cases_int.columns = ['Date', 'Cases']\n",
    "    cases = cases_int.groupby('Date', as_index = False)['Cases'].sum()\n",
    "    \n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError\n",
    "    \n",
    "    total = pd.merge(deaths, cases, on = 'Date', how = 'inner')  \n",
    "    total['Date'] = total['Date'].map(lambda x : x.month)\n",
    "    liberia_frame = liberia_frame.append(total)\n",
    "    \n",
    "#In December, the total cases & new cases are exchanged and no values for the new cases are provided\n",
    "#We approximate those values by taking the difference of total values over multiple dates\n",
    "liberia_frame.loc[(liberia_frame.Cases > 1000 ),'Cases'] =\\\n",
    "    liberia_frame[[d > 1000 for d in liberia_frame.Cases]]['Cases'].diff(periods=1)\n",
    "\n",
    "liberia_frame['Country'] = 'Liberia'    \n",
    "\n",
    "print('Getting all rows : ' , \n",
    "      liberia_frame.Deaths.shape[0] == len(os.listdir(path + 'liberia_data')))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final part of data cleaning is dedicated to the Sierra Leone files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sl_frame = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path + 'sl_data'):\n",
    "    frame = pd.read_csv(path + 'sl_data/' + filename, parse_dates=['date'],\n",
    "                       usecols=['date', 'variable', 'National'])\n",
    "    \n",
    "    #These csv files do not count the number of new cases\n",
    "    #We find an approximate value by taking the difference between two consecutive days registered\n",
    "    deaths = frame[[d in ['death_suspected','death_probable','death_confirmed' ]\n",
    "                    for d in frame.variable]][['date', 'variable', 'National']]\n",
    "\n",
    "    deaths.National = deaths.National.astype(float) #Needed to deal well with nan values\n",
    "    deaths = deaths.groupby('date', as_index = False)['National'].sum() #Summing over 3 possible types of death\n",
    "    deaths.columns = ['Date', 'Total Deaths']\n",
    "    \n",
    "    cases = frame[[d in ['new_suspected','new_probable','new_confirmed' ]\n",
    "                    for d in frame.variable]][['date', 'variable', 'National']]\n",
    "    cases.dropna(axis='rows') #Dealing with na values\n",
    "    cases.National = cases.National.map(\n",
    "        lambda x: x if type(x) is float else x.replace(',', '')) #If the string contains ','; remove it\n",
    "    cases.National = cases.National.astype(float) #Needed to sum\n",
    "    cases = cases.groupby('date', as_index = False)['National'].sum()\n",
    "    cases.columns = ['Date', 'Cases']\n",
    "    \n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError\n",
    "    \n",
    "    total = pd.merge(deaths, cases, on = 'Date', how = 'inner')  \n",
    "    total['Date'] = total['Date'].map(lambda x : x.month)\n",
    "    sl_frame = sl_frame.append(total) \n",
    "\n",
    "sl_frame.reset_index(drop = True, inplace = True)\n",
    "new_deaths = sl_frame['Total Deaths'].diff(periods=1) \n",
    "sl_frame['Deaths'] = new_deaths #Set the new deaths\n",
    "del sl_frame['Total Deaths'] #Drop the Total Deaths (not needed for our element)\n",
    "\n",
    "sl_frame.loc[((sl_frame.Deaths < 0)), 'Deaths'] = float('nan') #Clearly we can't have negative deaths\n",
    "sl_frame.loc[((sl_frame.Deaths > 200)), 'Deaths'] = float('nan')#We drop the strong outliers (2) in the dataset\n",
    "\n",
    "sl_frame['Country'] = 'Sierra Leone'\n",
    "\n",
    "print('Getting all rows : ' , \n",
    "    sl_frame.Cases.shape[0] == len(os.listdir(path + 'sl_data')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clean values for all three countries, we can easily put them together and calculate the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MERGING ALL FRAMES\n",
    "ebola_deaths_cases = pd.concat([guinea_frame, liberia_frame, sl_frame]).reset_index(drop = True)\n",
    "ebola_deaths_cases.Deaths = ebola_deaths_cases.Deaths.astype(float)\n",
    "ebola_deaths_cases.Cases = ebola_deaths_cases.Cases.astype(float)\n",
    "means = ebola_deaths_cases.groupby(['Date', 'Country'], as_index = False)[['Deaths', 'Cases']].mean()\n",
    "\n",
    "#We are asked to calculate the means, we sort them for convenience\n",
    "means.sort_values(by='Country', ascending = 1).set_index(['Country', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some figures (for fun!) used to visualize our data and make sure the results are consistent\n",
    "plt.figure();\n",
    "grouped_means = means.groupby('Country')\n",
    "grouped_means.get_group('Guinea').plot(x = 'Date', title = 'Guinea')\n",
    "grouped_means.get_group('Liberia').plot(x = 'Date', title = 'Liberia')\n",
    "grouped_means.get_group('Sierra Leone').plot(x = 'Date', title = 'Sierra Leone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS** answer: <br/> \n",
    "To make sure the 'cleaned' data makes sense (that there are no negative deaths or cases etc.), I used a simple bar graphs to check everything in one glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ebola_deaths_cases.groupby('Country').plot(x ='Date', kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Comentary:\n",
    "\n",
    "The idea for the first part of this exercise is to merge all the files and to name each column imported using the namefile (it will be easier to tag all columns using the barcode at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_frame = pd.DataFrame() # Creation of the aggregate (as in the exercises)\n",
    "aggregated_frame.index.name = 'Taxon' # Tagging the index to be able to join the frames\n",
    "\n",
    "for i in range(1, 10):\n",
    "    filename = 'MID' + str(i) # Defined as a variable to be able to tag the columns\n",
    "    temp_frame = pd.read_excel(DATA_FOLDER + '/microbiome/' + filename + '.xls','Sheet 1', index_col=0, header=None)\n",
    "    temp_frame.columns = [filename]\n",
    "    temp_frame.index.name = 'Taxon'\n",
    "    aggregated_frame = aggregated_frame.join(temp_frame, how='outer') #Joining frames\n",
    "    \n",
    "aggregated_frame #Show intermediate DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part, we import the Metadata (and clean it) before merging it in the third part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER + '/microbiome/metadata.xls','Sheet1', index_col=0)\n",
    "metadata = metadata.fillna('NA') #As the 'NA' is translated to 'NaN', we decided to name 'NA' as to differentiate it\n",
    "                                    #from the unknown objects and stick with the metadata\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final part, we group the elements by the values given in the metadata file and replace the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_frame = aggregated_frame.T.join(metadata) #Allows us to easily join with metadata\n",
    "final_frame = aggregated_frame.set_index(['SAMPLE', 'GROUP']).T #We group the elements and obtain the desired shape\n",
    "final_frame = final_frame.fillna('unknown') #This is the last step as required\n",
    "final_frame #Display final frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "1. Instead of iterating on the indexes each file, we could use the barcode of the metadata to iterate over each file and give the possibility to add more files without having to change the code\n",
    "2. We did not know if we should have tagged the 'NA' value in the SAMPLE column as 'unkwown' or if we should have kept the name, so we decided to stick with the name\n",
    "3. To group the elements, we thought it best to define the SAMPLE as the supergroup as it contained more columns than the GROUP (easier visualization), but it is easy to change them and order them according to each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')\n",
    "\n",
    "# Importing the xls file\n",
    "titanicXls = pd.read_excel(DATA_FOLDER+'/titanic.xls', header=0)\n",
    "# See what the data looks like\n",
    "titanicXls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's go in order for each colum :\n",
    "0. pclass is the level they were on: either first, second or third class (1, 2, 3).\n",
    "1. Survived, which can take either 0 or 1 (so yes or no).\n",
    "2. Name which can take any string. Begins with a last name, then a comma, than the title (Miss, Mr. Master...) and the first name(s).\n",
    "3. Sex, which can be either male or female.\n",
    "4. Age, which can take any number (double).\n",
    "5. sibsp is the number of siblings aboard of the titanic and can take any integer.\n",
    "6. parch is the number of parents aboard of the titanic and can take any integer.\n",
    "7. ticket which is the ticket number. Can take any integer, sometimes preceded with letters. Several members of a same family can share one.\n",
    "8. fare, which is the amount paid for the ticket (double).\n",
    "9. cabin which contains the cabin letter and number. Can have several of them.\n",
    "10. embarked is where somone has embarked and can take the initials S, C or Q.\n",
    "11. boat which is the escape boat they were on. Can either be an integer, a character, a mix of both or NaN (usually if survived = 0).\n",
    "12. body which is either a number or NaN. Represent if the body was found and if it was, which number (body indentification number) it was. \n",
    "13. home.dest is the destination there were going to. Can take any string (addresses).\n",
    "(Note that all these informations can be found in the html file).\n",
    "\n",
    "So with these informations, we can determine which attributes are *Categorical* knowing that they are anything with a fix number that we can simply enumerate. Thus, pclass, survived, sex, cabin, embarked and boat are all categorical.\n",
    "We could also say that age, fare and body could all be Categorical, as we have a fixed limit of different possibilities for each of them.\n",
    "Home.dest could have been Categorical if we only had states from the USA (as there is a fixed number of them) but it is harder to transform seeing as we have other destinations (like Canada or France)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Easy to do travel class as we have three integers. We can simply use an histogram\n",
    "plt.title('Travel Class')\n",
    "titanicXls.pclass.value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "#for embarked and sex, we need to have bar charts, as we do not have numerical values.\n",
    "plt.title('Embarked')\n",
    "titanicXls.embarked.value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Sex')\n",
    "titanicXls.sex.value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Histogram does the work for us.\n",
    "plt.title('Age')\n",
    "titanicXls.age.hist(grid=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "\n",
    "I take in consideration that each floor is the first character (A to G + T) and only take into account the first character as the floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean the NaN\n",
    "cabins = pd.DataFrame(titanicXls.cabin.dropna())\n",
    "# Determine the floor for each row\n",
    "cabins['Floor'] = cabins['cabin'].str[:1]\n",
    "#Plot the values.\n",
    "plt.title('Passengers by Cabin Floor')\n",
    "cabins['Floor'].value_counts().plot.pie(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "\n",
    "I take into consideration that 1 is a yes for survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take only the interesting columns.\n",
    "survivalByClass = titanicXls.iloc[:, 0:2]\n",
    "# Clean it from the NaN\n",
    "survivalByClass = pd.DataFrame(survivalByClass.dropna())\n",
    "\n",
    "#take only the interesting rows: those that have survival = 1\n",
    "survived = survivalByClass.loc[survivalByClass['survived'] == 1]\n",
    "plt.title('Survived by Class')\n",
    "survived['pclass'].value_counts().plot.pie(figsize=(5, 5), colors=['#ff7f0e', '#2ca02c', '#1f77b4'])\n",
    "plt.show()\n",
    "\n",
    "#for fun, here are all the deads by class\n",
    "iseedeadpeople = survivalByClass.loc[survivalByClass['survived'] == 0]\n",
    "plt.title('Dead by Class')\n",
    "iseedeadpeople['pclass'].value_counts().plot.pie(figsize=(5, 5), colors=['#2ca02c', '#1f77b4','#ff7f0e'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take only the interesting columns\n",
    "survivalBySex = titanicXls.iloc[:, [0,1,3]]\n",
    "# Take out all NaN\n",
    "survivalBySex = pd.DataFrame(survivalBySex.dropna())\n",
    "\n",
    "# Take only those that survived\n",
    "survivedSex = survivalBySex.loc[survivalBySex['survived'] == 1]\n",
    "survivedSex = survivedSex.iloc[:, [0, 2]]\n",
    "\n",
    "# Using a few stackoverflow questions, be able to create a crosstab so that we can get alive sex by class\n",
    "aliveSexByClass = pd.crosstab(survivedSex.sex, survivedSex.pclass)\n",
    "\n",
    "# Use another to get a usable plot\n",
    "stacked = aliveSexByClass.stack().reset_index().rename(columns={0:'value'})\n",
    "plt.title('Survived by Class')\n",
    "sns.barplot(x=stacked.sex, y=stacked.value, hue=stacked.pclass)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Just for fun, same for dead !\n",
    "# Take only those that survived\n",
    "deadSex = survivalBySex.loc[survivalBySex['survived'] == 0]\n",
    "deadSex = deadSex.iloc[:, [0, 2]]\n",
    "\n",
    "# Using a few stackoverflow questions, be able to create a crosstab so that we can get alive sex by class\n",
    "deadSexByClass = pd.crosstab(deadSex.sex, deadSex.pclass)\n",
    "\n",
    "# Use another to get a usable plot\n",
    "stacked2 = deadSexByClass.stack().reset_index().rename(columns={0:'value'})\n",
    "plt.title('Dead by Class')\n",
    "sns.barplot(x=stacked2.sex, y=stacked2.value, hue=stacked2.pclass)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take only the interesting columns\n",
    "survivalByAge = titanicXls.iloc[:, [0,1,3,4]]\n",
    "# Take out all NaN\n",
    "survivalByAge = pd.DataFrame(survivalByAge.dropna())\n",
    "# Sort by Age\n",
    "survivalByAge = survivalByAge.sort_values('age')\n",
    "\n",
    "# We have 1046 rows in this DataFrame. Thus, the 523 first rows are the first category. The 523 last are the second.\n",
    "# Lets thus replace the age of everyone by 1 for the first category and 2 for the second.\n",
    "# As category we will put the mean age of the category.\n",
    "n = len(survivalByAge)\n",
    "survivalByAge.loc[:n/2, 'age'] = survivalByAge.loc[:n/2, 'age'].mean()\n",
    "survivalByAge.loc[(n/2):, 'age'] = survivalByAge.loc[(n/2):, 'age'].mean()\n",
    "\n",
    "# This will do the mean for each group/category we want, as we have only 0 or 1.\n",
    "groupedSurvival = survivalByAge.groupby(['age', 'sex', 'pclass'])['survived'].mean()\n",
    "survivalByAgeDF = pd.DataFrame(groupedSurvival)\n",
    "survivalByAgeDF"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
