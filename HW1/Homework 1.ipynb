{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os #I want to read all files in doc automaticaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Comentary:\n",
    "\n",
    "As all the csv files are structured in very different ways, I cleaned all data for each country individualy before merging it into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = DATA_FOLDER + '/ebola/'\n",
    "\n",
    "#I procede to go though each folder, starting with guinea\n",
    "\n",
    "guinea_frame = pd.DataFrame()\n",
    "for filename in os.listdir(path+'guinea_data'):\n",
    "    frame = pd.read_csv(path+'guinea_data/'+filename, parse_dates=['Date'],\n",
    "                        usecols=['Date', 'Description', 'Totals'])#keep only the 3 relevant colums\n",
    "    \n",
    "    deaths = frame[['New deaths registered' in d for d in frame.Description]\n",
    "                  ][['Date', 'Totals']].drop_duplicates(subset='Date')\n",
    "    \n",
    "    cases= frame[['Total new cases' in d for d in frame.Description]][['Date', 'Totals']]\n",
    "\n",
    "    deaths.columns = ['Date', 'Deaths']\n",
    "    cases.columns = ['Date', 'Cases']\n",
    "    \n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError #make sure that we get the same number of values per file\n",
    "                            #will be one row per date/csv file\n",
    "    \n",
    "    total = pd.merge(deaths, cases, on='Date', how='inner')\n",
    "    total['Date'] = total['Date'].map(lambda x : x.month) #we only want to know about the month (all csv set in 2014)\n",
    "    guinea_frame = guinea_frame.append(total)\n",
    "\n",
    "guinea_frame['Country'] = 'Guinea'\n",
    "\n",
    "#make sure we get some data from every document & we don't miss rows\n",
    "print('Getting all rows : ',\n",
    "      guinea_frame.Deaths.shape[0] == len(os.listdir(path+'guinea_data')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part treats the data from Liberia. Overall, the transcription contains a lot of inconsistencies,\n",
    "which were adressed by treating cases seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberia_frame = pd.DataFrame()\n",
    "cumulative_cases = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path+'liberia_data'):\n",
    "    frame = pd.read_csv(path+'liberia_data/'+filename, parse_dates=['Date'],\n",
    "                       usecols=['Date', 'Variable', 'National']) #get only the 3 relevant colums\n",
    "    \n",
    "    #one csv contains duplicates on the variable column\n",
    "    #As the values differ I assumed that the first value is the correct one\n",
    "    frame = frame.drop_duplicates(subset='Variable') \n",
    "    \n",
    "    deaths = frame[[d in 'Newly reported deaths' for d in frame.Variable]][['Date', 'National']]\n",
    "    deaths.columns = ['Date', 'Deaths']\n",
    "    \n",
    "    #we get all 3 values of new cases (suspected, probable and confirmed) & sum them up\n",
    "    cases_int = frame[['New Case/s'.lower() in d.lower() for d in frame.Variable]][['Date', 'National']]  \n",
    "    cases_int.columns = ['Date', 'Cases'] #renaming for convenience\n",
    "    cases = cases_int.groupby('Date', as_index=False)['Cases'].sum()\n",
    "    \n",
    "    #make sure that there is no error in the rows we're getting\n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError\n",
    "    \n",
    "    total = pd.merge(deaths, cases, on='Date', how='inner')  \n",
    "    total['Date'] = total['Date'].map(lambda x : x.month)\n",
    "    liberia_frame = liberia_frame.append(total)\n",
    "    \n",
    "#in december, the total cases & new cases are exchanged, no values for the new cases are provided\n",
    "#we approximate those values by taking the difference of total values over multiple dates\n",
    "liberia_frame.loc[(liberia_frame.Cases > 1000 ),'Cases'] =\\\n",
    "    liberia_frame[[d > 1000 for d in liberia_frame.Cases]]['Cases'].diff(periods=1)\n",
    "\n",
    "liberia_frame['Country'] = 'Liberia'    \n",
    "\n",
    "print('Getting all rows : ' , \n",
    "      liberia_frame.Deaths.shape[0] == len(os.listdir(path+'liberia_data')))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with sierra leone files\n",
    "\n",
    "sl_frame = pd.DataFrame()\n",
    "for filename in os.listdir(path+'sl_data'):\n",
    "    frame = pd.read_csv(path+'sl_data/'+filename, parse_dates=['date'],\n",
    "                       usecols=['date', 'variable', 'National'])\n",
    "    #these csv files do not count the number of new cases\n",
    "    #we find an approximate value by taking the difference between two consequitive days registered\n",
    "    deaths = frame[[d in ['death_suspected','death_probable','death_confirmed' ]\n",
    "                    for d in frame.variable]][['date', 'variable', 'National']]\n",
    "\n",
    "    deaths.National = deaths.National.astype(float) #as to deal well with nan values\n",
    "    deaths = deaths.groupby('date', as_index=False)['National'].sum() #summing over 3 possible types of death\n",
    "    \n",
    "    \n",
    "    cases = frame[[d in ['new_suspected','new_probable','new_confirmed' ]\n",
    "                    for d in frame.variable]][['date', 'variable', 'National']]\n",
    "    \n",
    "    cases.dropna(axis='rows') #dealing with na values\n",
    "    cases.National = cases.National.map(\n",
    "        lambda x: x if type(x) is float else x.replace(',', '')) #if string contains , remove it\n",
    "    \n",
    "    cases.National = cases.National.astype(float) #needed to sum\n",
    "    cases = cases.groupby('date', as_index=False)['National'].sum()\n",
    "    \n",
    "    cases.columns = ['Date', 'Cases']\n",
    "    deaths.columns = ['Date', 'Total Deaths']\n",
    "    \n",
    "    if(cases.shape != deaths.shape):\n",
    "        raise AssertionError\n",
    "    \n",
    "    total = pd.merge(deaths, cases, on='Date', how='inner')  \n",
    "    total['Date'] = total['Date'].map(lambda x : x.month)\n",
    "    \n",
    "    sl_frame = sl_frame.append(total)#aggregate all csv files\n",
    "\n",
    "sl_frame.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#calculate new deaths by taking difference between consequitive total deaths\n",
    "new_deaths = sl_frame['Total Deaths'].diff(periods=1) \n",
    "\n",
    "sl_frame['Deaths'] = new_deaths #set new deaths\n",
    "del sl_frame['Total Deaths']\n",
    "\n",
    "sl_frame.loc[((sl_frame.Deaths < 0)), 'Deaths'] = float('nan') #clearly we can't have negative deaths\n",
    "sl_frame.loc[((sl_frame.Deaths > 200)), 'Deaths'] = float('nan')#strong outliers (2) in dataset\n",
    "\n",
    "sl_frame['Country'] = 'Sierra Leone'\n",
    "\n",
    "print('Getting all rows : ' , \n",
    "    sl_frame.Cases.shape[0] == len(os.listdir(path+'sl_data')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clean values for all three countries, we can easily put them together and calculate the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGING ALL FRAMES\n",
    "ebola_deaths_cases = pd.concat([guinea_frame, liberia_frame, sl_frame]).reset_index(drop=True)\n",
    "ebola_deaths_cases.Deaths = ebola_deaths_cases.Deaths.astype(float)\n",
    "ebola_deaths_cases.Cases = ebola_deaths_cases.Cases.astype(float)\n",
    "means = ebola_deaths_cases.groupby(['Date', 'Country'], as_index=False)[['Deaths', 'Cases']].mean()\n",
    "\n",
    "means.sort_values(by='Country', ascending=1).set_index(['Country', 'Date']) #the means we were asked to calculate, sort for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some figures (for fun!)\n",
    "plt.figure();\n",
    "grouped_means = means.groupby('Country')\n",
    "grouped_means.get_group('Guinea').plot(x='Date', title='Guinea')\n",
    "grouped_means.get_group('Liberia').plot(x='Date', title='Liberia')\n",
    "grouped_means.get_group('Sierra Leone').plot(x='Date', title='Sierra Leone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS answer: \n",
    "to make sure the 'cleaned' data makes sense (no negative deaths or cases etc.) I used a simple bar graphs to check at one glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_deaths_cases.groupby('Country').plot(x='Date', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Comentary:\n",
    "\n",
    "The idea for the first part of this exercise is to merge all the files and to name each column imported using the namefile (it will be easier to tag all columns using the barcode at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_frame = pd.DataFrame() # Creation of the aggregate (as in the exercises)\n",
    "aggregated_frame.index.name = 'Taxon' # Tagging the index to be able to join the frames\n",
    "\n",
    "for i in range(1, 10):\n",
    "    filename = 'MID' + str(i) # Defined as a variable to be able to tag the columns\n",
    "    temp_frame = pd.read_excel(DATA_FOLDER + '/microbiome/' + filename + '.xls','Sheet 1', index_col=0, header=None)\n",
    "    temp_frame.columns = [filename]\n",
    "    temp_frame.index.name = 'Taxon'\n",
    "    aggregated_frame = aggregated_frame.join(temp_frame, how='outer') #Joining frames\n",
    "    \n",
    "aggregated_frame #Show intermediate DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part, we import the Metadata (and clean it) before merging it in the third part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER + '/microbiome/metadata.xls','Sheet1', index_col=0)\n",
    "metadata = metadata.fillna('NA') #As the 'NA' is translated to 'NaN', we decided to name 'NA' as to differentiate it\n",
    "                                    #from the unknown objects and stick with the metadata\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final part, we group the elements by the values given in the metadata file and replace the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_frame = aggregated_frame.T.join(metadata) #Allows us to easily join with metadata\n",
    "final_frame = aggregated_frame.set_index(['SAMPLE', 'GROUP']).T #We group the elements and obtain the desired shape\n",
    "final_frame = final_frame.fillna('unknown') #This is the last step as required\n",
    "final_frame #Display final frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "1. Instead of iterating on the indexes each file, we could use the barcode of the metadata to iterate over each file and give the possibility to add more files without having to change the code\n",
    "2. We did not know if we should have tagged the 'NA' value in the SAMPLE column as 'unkwown' or if we should have kept the name, so we decided to stick with the name\n",
    "3. To group the elements, we thought it best to define the SAMPLE as the supergroup as it contained more columns than the GROUP (easier visualization), but it is easy to change them and order them according to each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')\n",
    "\n",
    "# Importing the cls file\n",
    "titanicXls = pd.read_excel(DATA_FOLDER+'/titanic.xls', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
