{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the data folder to look for the saved rankings\n",
    "DATA_FOLDER = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import os #we can write this better\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define nice helper functions to reduce the running time\n",
    "import pickle\n",
    "def save_pkl(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the aproptiate links to find the data, we did a preliminary explosation of the websides responses and code using postman and the google chrome dev tools.\n",
    "\n",
    "- For the times, going to the ranking site and looking at the json response immediatly led to the right data.\n",
    "- For the topuniversities, a search on postman looking for the occurence of the string data was preformed, leading to the source of the data\n",
    "- To find the additioal information needed in the topuniversities set, we used the google dev tools to quickly check which classes pointed to the < div> tags containing the required information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first find the appropriate lists giving us the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base URL for websites to crawl\n",
    "TIMES_EDUCATION = 'https://www.timeshighereducation.com'\n",
    "TOP_UNIVERSITIES = 'https://www.topuniversities.com'\n",
    "FILES = '/sites/default/files/'\n",
    "\n",
    "#These are the main URLs we will be working with\n",
    "TIMES_EDUCATION_JSON = TIMES_EDUCATION + FILES + 'the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "TOP_UNIVERVERSITIES_TEXT = TOP_UNIVERSITIES + FILES + 'qs-rankings-data/357051.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we request the JSON of the first ranking and preprocess the data (the steps are detailed in the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We send the request and save the JSON\n",
    "r = requests.get(TIMES_EDUCATION_JSON)\n",
    "timesjson = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming to Data frame\n",
    "times_frame = pd.DataFrame(timesjson['data']).head(200) #Keep the first 200 schools\n",
    "times_frame = times_frame[[d for d in times_frame.columns if not ('score' in d)]] #Drop useless frames\n",
    "del times_frame['member_level'],\\\n",
    "    times_frame['nid'],\\\n",
    "    times_frame['record_type'],\\\n",
    "    times_frame['subjects_offered'],\\\n",
    "    times_frame['stats_female_male_ratio']\n",
    "times_frame['rank_order'] = times_frame['rank_order'].map(lambda x: int(int(x)/10)) #Keeping absolute order\n",
    "\n",
    "#We display the format of the elements we retrieved to get a better visualization\n",
    "times_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_frame.shape #getting 200 universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply repeat the same process for the second ranking (thus, we will not comment the code as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = requests.get(TOP_UNIVERVERSITIES_TEXT)\n",
    "topjson = s.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##NEED TO GET ONLY NUMERICAL VALUES FOR THE RANK DISPLAY!!\n",
    "\n",
    "top_frame = pd.DataFrame(topjson['data']).head(200)\n",
    "del top_frame['cc'],\\\n",
    "    top_frame['logo'],\\\n",
    "    top_frame['nid'],\\\n",
    "    top_frame['core_id'],\\\n",
    "    top_frame['stars'],\\\n",
    "    top_frame['guide'] \n",
    "\n",
    "top_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to find additional elements, we need to visit every University URL. Below, we offer an example of usage (1st university of the Top Universities ranking) in order to clarify the code we will write in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(TOP_UNIVERSITIES + '/universities/university-cambridge')\n",
    "page_body = r.text\n",
    "soup = BeautifulSoup(page_body, 'html.parser')\n",
    "\n",
    "#In order to get the right numbers, we use [1:-1] in order to delete the leading and trailing spaces\n",
    "student_number = (soup.find('div', class_='total student')).find('div', class_='number').text[1:-1]\n",
    "int_student = (soup.find('div', class_='total inter')).find('div', class_='number').text[1:-1]\n",
    "facult_number = (soup.find('div', class_='total faculty')).find('div', class_='number').text[1:-1]\n",
    "int_faculty = (soup.find('div', class_='inter faculty')).find('div', class_='number').text[1:-1]\n",
    "\n",
    "#We create a new DataFrame to visualize the new information\n",
    "pd.DataFrame.from_dict({'students' : [student_number], \n",
    "              'international students': [int_student], \n",
    "              'faculty' : [facult_number], \n",
    "              'international faculty' : [int_faculty] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As asked, we need to ensure that we have the name, rank, country & region, number of faculty members (international and total) and number of students (international and total) and that they appear in the final DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_additional_info(url):\n",
    "    r = requests.get(TOP_UNIVERSITIES + url)\n",
    "    if r.status_code == 404:\n",
    "        print('NOOO')\n",
    "    page_body = r.text\n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    #In the following steps, we make sure the values exist before fetching them\n",
    "    student_number = (soup.find('div', class_='total student')) \n",
    "    if student_number:\n",
    "        student_number = student_number.find('div', class_='number')\n",
    "        \n",
    "    int_student = (soup.find('div', class_='total inter'))\n",
    "    if int_student:\n",
    "        int_student = int_student.find('div', class_='number')\n",
    "    \n",
    "    faculty_number = (soup.find('div', class_='total faculty'))\n",
    "    if faculty_number:\n",
    "        faculty_number = faculty_number.find('div', class_='number')\n",
    "        \n",
    "    int_faculty = (soup.find('div', class_='inter faculty'))\n",
    "    if int_faculty:\n",
    "        int_faculty = int_faculty.find('div', class_='number')\n",
    "    \n",
    "    frame = pd.DataFrame.from_dict({'students' : [remove_blank_convert_float(student_number)], \n",
    "              'international students': [remove_blank_convert_float(int_student)], \n",
    "              'faculty' : [remove_blank_convert_float(faculty_number)], \n",
    "              'international faculty' : [remove_blank_convert_float(int_faculty)] })\n",
    "    return frame\n",
    "\n",
    "\n",
    "def remove_blank_convert_float(x):\n",
    "    if(x):\n",
    "        x = x.text[1:-1].replace(\",\",\"\")\n",
    "        x_float = float(x)\n",
    "    else:\n",
    "        #use nan for unknown values, facilitates computation\n",
    "        x_float = float('nan')\n",
    "    return x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes a relatively long time to run the first time\n",
    "\n",
    "#create place to put data\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "\n",
    "top_file = DATA_FOLDER + 'top_ranking.pkl'\n",
    "if exists(top_file):\n",
    "    merged_top = load_pkl(top_file)\n",
    "else :\n",
    "    missing_rows = pd.DataFrame()\n",
    "    for url in top_frame.url:\n",
    "        new_info = get_additional_info(url)\n",
    "        missing_rows = missing_rows.append(new_info, ignore_index = True)\n",
    "    merged_top = pd.concat([top_frame, missing_rows], axis=1, join_axes=[top_frame.index])\n",
    "    save_pkl(merged_top, top_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if we have any undefined values in the set and see that we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top.shape #geting 200 universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top[merged_top.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have undefined values, but they are due to the wbesite not containing these informations.\n",
    "For now, we propagate the nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try to determine which university is best according to the faculty/student ratio. To do that, we create a new DataFrame which only contains the name of the university, the ratio and the rank_display in case of a tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_fac_stud = merged_top\n",
    "top_fac_stud['faculty/students'] = top_fac_stud.faculty/top_fac_stud.students\n",
    "top_fac_stud = top_fac_stud[['title', 'faculty/students', 'rank_display']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fac_stud = top_fac_stud.sort_values(['faculty/students', 'rank_display'], ascending=[False, True])\n",
    "top_fac_stud.index = range(len(top_fac_stud.index))\n",
    "top_fac_stud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we sort the universities according to their international students ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_int_stud = merged_top\n",
    "top_int_stud['international/students'] =\\\n",
    "    top_int_stud['international students']/top_int_stud['students']\n",
    "top_int_stud = top_int_stud[['title', 'international/students', 'rank_display']]\n",
    "top_int_stud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_int_stud = top_int_stud.sort_values(['international/students', 'rank_display'], ascending=[False, True])\n",
    "top_int_stud.index = range(len(top_fac_stud.index))\n",
    "top_int_stud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to aggregate the universities by country and region in order to sort them by ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##AS RANK DOESN'T WORK (NOT NUMERICAL VALUES ONLY ) WE USE THE SCORE\n",
    "top_country = merged_top.sort_values(['country', 'score'], ascending=[True,False])\n",
    "top_country.set_index('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to work on it (cf Above)\n",
    "top_region = merged_top\n",
    "top_region = top_region.groupby(\"region\", as_index = False)[\"score\"].max()\n",
    "top_region = top_region.sort_values(\"score\", ascending = False)\n",
    "top_region.index = range(len(top_region.index))\n",
    "top_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to define the regions by country, we define a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions_by_country = dict(zip(top_frame.country, top_frame.region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_frame['region'] = times_frame.location.map(regions_by_country)\n",
    "times_frame[times_frame.region.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both are in Europe, amd Luxembourg isn't present anyway\n",
    "times_frame.loc[times_frame.region.isnull(), 'region'] = 'Europe' \n",
    "times_frame[times_frame.location == 'Luxembourg'] #assignment works :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the rank as an int, so we use replace and a regex to be able to only have int values.\n",
    "# CARTEFUL: can only run this once or you will have errors ! Because .str only works on strings and we transform to int!\n",
    "times_frame['rank'] = times_frame['rank'].str.replace(r'\\D+', '').astype('int')\n",
    "top_frame['rank_display'] = top_frame['rank_display'].str.replace(r'\\D+', '').astype('int')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
