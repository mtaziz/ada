{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the data folder to look for the saved rankings\n",
    "DATA_FOLDER = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from os.path import exists\n",
    "import os #we can write this better\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define a few helper functions to reduce running time\n",
    "def save_pkl(obj, path):\n",
    "    \"\"\"Saves into a pickle file to given path.\"\"\"\n",
    "    with open(path, 'wb') as f:\n",
    "        pk.dump(obj, f)\n",
    "        \n",
    "def load_pkl(path):\n",
    "    \"\"\"Loads a pickle file from a given path.\"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        return pk.load(f)\n",
    "\n",
    "    \n",
    "# We have several ratios to calculate, so we will have a function that does it.\n",
    "def ratios_calc(df, c1, c2, name):\n",
    "    \"\"\"Function that calculates ratios of given panda dataframe.\n",
    "        df is the dataframe\n",
    "        c1 is the name of the first column for the ratio,\n",
    "        c2 is the name of the second column for the ratio,\n",
    "        name is the name of the new column\n",
    "    \"\"\"\n",
    "    # Calculate ratio and put it in a new column\n",
    "    df[name] = df[c1]/df[c2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the approptiate links to find the data, we did a preliminary exploration of the website's responses and code using postman and the google chrome dev tools.\n",
    "\n",
    "- For the Times, going to the ranking site and looking at the JSON response immediatly led to the right data.\n",
    "- For TopUniversities, a search on postman looking for the occurence of the string data was preformed, leading to the source of the data\n",
    "- To find the additioal information needed in the topuniversities set, we used the google dev tools to quickly check which classes pointed to the div tags containing the required information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first find the appropriate lists giving us the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base URL for websites to crawl\n",
    "TIMES_EDUCATION = 'https://www.timeshighereducation.com'\n",
    "TOP_UNIVERSITIES = 'https://www.topuniversities.com'\n",
    "FILES = '/sites/default/files/'\n",
    "\n",
    "#These are the main URLs we will be working with\n",
    "TIMES_EDUCATION_JSON = TIMES_EDUCATION + FILES + 'the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "TOP_UNIVERVERSITIES_TEXT = TOP_UNIVERSITIES + FILES + 'qs-rankings-data/357051.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we request the JSON of the first ranking and preprocess the data (the steps are detailed in the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We send the request and save the JSON\n",
    "r = requests.get(TIMES_EDUCATION_JSON)\n",
    "timesjson = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming to Data frame\n",
    "times_frame = pd.DataFrame(timesjson['data']).head(200) #Keep the first 200 schools\n",
    "times_frame = times_frame[[d for d in times_frame.columns if not ('score' in d)]] #Drop useless frames\n",
    "del times_frame['member_level'],\\\n",
    "    times_frame['nid'],\\\n",
    "    times_frame['record_type'],\\\n",
    "    times_frame['subjects_offered'],\\\n",
    "    times_frame['stats_female_male_ratio']\n",
    "times_frame['rank_order'] = times_frame['rank_order'].map(lambda x: int(int(x)/10)) #Keeping absolute order\n",
    "\n",
    "#We display the format of the elements we retrieved to get a better visualization\n",
    "times_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_frame.shape #getting 200 universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply repeat the same process for the second ranking (thus, we will not comment the code as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = requests.get(TOP_UNIVERVERSITIES_TEXT)\n",
    "topjson = s.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_frame = pd.DataFrame(topjson['data']).head(200)\n",
    "del top_frame['cc'],\\\n",
    "    top_frame['logo'],\\\n",
    "    top_frame['nid'],\\\n",
    "    top_frame['core_id'],\\\n",
    "    top_frame['stars'],\\\n",
    "    top_frame['guide'] \n",
    "\n",
    "top_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want the rank to be clean, which means not having any string values (such as for example \"=3\" as two universites are at rank 3). We use a simple regex to quickly clean our dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want the rank as an int, so we use replace and a regex to be able to only have int values.\n",
    "# CARTEFUL: can only run this once or you will have errors ! Because .str only works on strings and we transform to int!\n",
    "times_frame['rank'] = times_frame['rank'].str.replace(r'\\D+', '').astype('int')\n",
    "top_frame['rank_display'] = top_frame['rank_display'].str.replace(r'\\D+', '').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to find additional elements, we need to visit every University URL. Below, we offer an example of usage (1st university of the Top Universities ranking) in order to clarify the code we will write in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just an example! we don't use this like this\n",
    "r = requests.get(TOP_UNIVERSITIES + '/universities/university-cambridge')\n",
    "page_body = r.text\n",
    "soup = BeautifulSoup(page_body, 'html.parser')\n",
    "\n",
    "#In order to get the right numbers, we use [1:-1] in order to delete the leading and trailing spaces\n",
    "\n",
    "student_number = (soup.find('div', class_='total student')).find('div', class_='number').text[1:-1]\n",
    "int_student = (soup.find('div', class_='total inter')).find('div', class_='number').text[1:-1]\n",
    "facult_number = (soup.find('div', class_='total faculty')).find('div', class_='number').text[1:-1]\n",
    "int_faculty = (soup.find('div', class_='inter faculty')).find('div', class_='number').text[1:-1]\n",
    "\n",
    "#We create a new DataFrame to visualize the new information\n",
    "pd.DataFrame.from_dict({'students' : [student_number], \n",
    "              'international students': [int_student], \n",
    "              'faculty' : [facult_number], \n",
    "              'international faculty' : [int_faculty] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As asked, we need to ensure that we have the name, rank, country & region, number of faculty members (international and total) and number of students (international and total) and that they appear in the final DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_additional_info(url):\n",
    "    r = requests.get(TOP_UNIVERSITIES + url)\n",
    "    assert r.status_code != 404, 'Bad request: could not get data'\n",
    "    page_body = r.text\n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    #In the following steps, we make sure the values exist before fetching them\n",
    "    student_number = (soup.find('div', class_='total student')) \n",
    "    if student_number:\n",
    "        student_number = student_number.find('div', class_='number')\n",
    "        \n",
    "    int_student = (soup.find('div', class_='total inter'))\n",
    "    if int_student:\n",
    "        int_student = int_student.find('div', class_='number')\n",
    "    \n",
    "    faculty_number = (soup.find('div', class_='total faculty'))\n",
    "    if faculty_number:\n",
    "        faculty_number = faculty_number.find('div', class_='number')\n",
    "        \n",
    "    int_faculty = (soup.find('div', class_='inter faculty'))\n",
    "    if int_faculty:\n",
    "        int_faculty = int_faculty.find('div', class_='number')\n",
    "    \n",
    "    frame = pd.DataFrame.from_dict({'students' : [remove_blank_convert_float(student_number)], \n",
    "              'international students': [remove_blank_convert_float(int_student)], \n",
    "              'faculty' : [remove_blank_convert_float(faculty_number)], \n",
    "              'international faculty' : [remove_blank_convert_float(int_faculty)] })\n",
    "    return frame\n",
    "\n",
    "\n",
    "def remove_blank_convert_float(x):\n",
    "    \"\"\"helper function, removes blankspace and parses to float\"\"\"\n",
    "    if(x):\n",
    "        x = x.text[1:-1].replace(\",\",\"\")\n",
    "        x_float = float(x)\n",
    "    else:\n",
    "        #use NAN for unknown values, facilitates computation\n",
    "        x_float = float('NAN')\n",
    "    return x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes a relatively long time to run the first time\n",
    "\n",
    "#create place to put data\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "\n",
    "top_file = DATA_FOLDER + 'top_ranking.pkl'\n",
    "if exists(top_file):\n",
    "    merged_top = load_pkl(top_file)\n",
    "else:\n",
    "    missing_rows = pd.DataFrame()\n",
    "    for url in top_frame.url:\n",
    "        new_info = get_additional_info(url)\n",
    "        missing_rows = missing_rows.append(new_info, ignore_index = True)\n",
    "    merged_top = pd.concat([top_frame, missing_rows], axis=1, join_axes=[top_frame.index])\n",
    "    save_pkl(merged_top, top_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if we have any undefined values in the set and see that we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top.shape #geting 200 universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_top[merged_top.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have undefined values, but they are due to the website not containing these informations. For now, we propagate the NAN values.\n",
    "\n",
    "We also want the ank to be an int so as to be able to do operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo: we should probably remove this line\n",
    "# We want the rank as an int, so we use replace and a regex to be able to only have int values.\n",
    "# CARTEFUL: can only run this once or you will have errors ! Because .str only works on strings and we transform to int!\n",
    "#merged_top['rank_display'] = merged_top['rank_display'].str.replace(r'\\D+', '').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try to determine which university is best according to the faculty/student ratio. To do that, we create a new DataFrame which only contains the name of the university, the ratio and the rank_display in case of a tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_fac_stud = merged_top\n",
    "ratios_calc(top_fac_stud,'faculty', 'students', 'faculty/students')\n",
    "top_fac_stud = top_fac_stud[['title', 'faculty/students', 'rank_display']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fac_stud = top_fac_stud.sort_values(['faculty/students', 'rank_display'], ascending=[False, True])\n",
    "top_fac_stud.index = range(len(top_fac_stud.index))\n",
    "top_fac_stud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we sort the universities according to their international students ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_int_stud = merged_top\n",
    "ratios_calc(top_int_stud,'international students', 'students', 'international/students')\n",
    "top_int_stud = top_int_stud[['title', 'international/students', 'rank_display']]\n",
    "top_int_stud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_int_stud = top_int_stud.sort_values(['international/students', 'rank_display'], ascending=[False, True])\n",
    "top_int_stud.index = range(len(top_fac_stud.index))\n",
    "top_int_stud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to aggregate the universities by country and region in order to sort them by ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_country = merged_top.sort_values(['country', 'rank_display'], ascending=[True,False])\n",
    "top_country.set_index('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to work on it (cf Above)\n",
    "top_region = merged_top\n",
    "top_region = top_region.groupby(\"region\", as_index = False)[\"score\"].max()\n",
    "top_region = top_region.sort_values(\"score\", ascending = False)\n",
    "top_region.index = range(len(top_region.index))\n",
    "top_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to define the regions by country, we define a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions_by_country = dict(zip(top_frame.country, top_frame.region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_frame['region'] = times_frame.location.map(regions_by_country)\n",
    "times_frame[times_frame.region.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both are in Europe, amd Luxembourg isn't present anyway\n",
    "times_frame.loc[times_frame.region.isnull(), 'region'] = 'Europe' \n",
    "times_frame[times_frame.location == 'Luxembourg'] #assignment works :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the two rangkings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first try to merge the two frames in a naive manner,\n",
    "We see that there is almost no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is a bad idea\n",
    "merged_frame = pd.merge(times_frame, \n",
    "                        merged_top, how='outer', right_on=['title'], left_on=['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So instead, we check if there is a python library to help us out. And there is! But we should probably ask if we are allowed to use this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import difflib \n",
    "\n",
    "def get_match(element, other):\n",
    "    #difflib gets the best matching elements and returns a list of possible matches in order of accuracy\n",
    "    match = difflib.get_close_matches(element, merged_top.title)\n",
    "    return '' if len(match) == 0 else match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = times_frame.name.map(lambda x: get_match(x, merged_top.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_frame['mergeindex'] = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_frame = pd.merge(times_frame, \n",
    "                        merged_top, how='outer', right_on=['title'], left_on=['mergeindex'])\n",
    "nulls = merged_frame[merged_frame.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_1 = nulls[nulls['name'].isnull()]\n",
    "nulls_2 = nulls[nulls['title'].isnull()]\n",
    "print(nulls_2.name)\n",
    "print(nulls_1[nulls_1['country'] == 'Germany'].title,\n",
    "nulls_2[nulls_2['location'] == 'Germany'].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nulls_1[nulls_1['country'] == 'France'].title,\n",
    "nulls_2[nulls_2['location'] == 'France'].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nulls_1[nulls_1['country'] == 'Sweden']['title'],\n",
    "nulls_2[nulls_2['location'] == 'Sweden']['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the only improvement possible is combining LMU Munich and Ludwig-Maximilians-Universität München, as this is one row, we just do it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: add rank? I don't think we need anything else, all other values are junk that won't be needed for question 4 and 5"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
