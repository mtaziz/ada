{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Steps\n",
    "\n",
    "We start the homework by importing the (many!) needed libraries and define functions that will help us later in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We import the same libraries as in the \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, GridSearchCV, PredefinedSplit\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function allows us to draw custom charts (and display them inline to be able to get useful insights). This will be used a lot throughout Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we use this a lot :D\n",
    "def drawPies(u_rates, t_rates, labels, supertitle):\n",
    "    \"\"\"draws pretty comparative pie charts\n",
    "    u_rates : rates for untreated group\n",
    "    t_rates : rates for treated group\n",
    "    lables: labels for values in rates\n",
    "    supertitle: title of chart\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    fig.suptitle(supertitle)\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.pie(u_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"untreated group\")\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.pie(t_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"treated group\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function we define is used to compare the interval variables (cf Exercises 1.02 and 1.04) of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interval_plots(df):\n",
    "    \"\"\"constructs boxplot and relative frequency histogram for data frame\n",
    "    df: dataframe to be analyzed\n",
    "    \"\"\"\n",
    "    #for each column draw a Boxplot\n",
    "    for col in intervals:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        treated_ = df[treated(df)][col]\n",
    "        untreated_ = df[untreated(df)][col]\n",
    "\n",
    "        #boxplot\n",
    "        plt.subplot(2,2,1)\n",
    "        plt.title(\"Boxplot of \" + col)\n",
    "        plt.boxplot([untreated_, treated_], \n",
    "                    labels=['untreated', 'treated'], showfliers=False)\n",
    "        plt.ylabel(col)\n",
    "\n",
    "        #histogram\n",
    "        plt.subplot(2,2,2)\n",
    "        bins = np.linspace(min(df[col]), max(lalonde_df[col]), 50)\n",
    "        plt.title(\"Relative frequency histogram of \" + col)\n",
    "        plt.ylabel('percentage')\n",
    "        plt.xlabel(col)\n",
    "        plt.hist(untreated_, weights=np.ones(len(untreated_))/len(untreated_), alpha=.5 , bins=bins)\n",
    "        plt.hist(treated_, weights=np.ones(len(treated_))/len(treated_), alpha=.5, bins=bins)\n",
    "        plt.legend(['untreated', 'treated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function is used in exercise 1.05 in order to compare the probabilities of categorical data between both groups (treated and untreated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_groups(table) :\n",
    "    \"\"\"\n",
    "    Compares groups in merged dataframe\n",
    "    table : dataframe to compare treated and untreated in\n",
    "    \"\"\"\n",
    "    columns = ['untreated', 'treated']\n",
    "    index = ['black', 'hisp', 'married', 'no_degree']\n",
    "    result = pd.DataFrame(columns=columns, index=index)\n",
    "    result['untreated']['black'] = table['black_y'].mean()\n",
    "    result['untreated']['hisp'] = table['hispan_y'].mean()\n",
    "    result['untreated']['married'] = table['married_y'].mean()\n",
    "    result['untreated']['no_degree'] = table['nodegree_y'].mean()\n",
    "    result['treated']['black'] = table['black_x'].mean()\n",
    "    result['treated']['hisp'] = table['hispan_x'].mean()\n",
    "    result['treated']['married'] = table['married_x'].mean()\n",
    "    result['treated']['no_degree'] = table['nodegree_x'].mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Propensity Score Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this exercise is to analyze a dataset first without any real knowledge (naive analysis) and then through multiple processing steps to understand the data further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the data (and displaying it to understand the format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lalonde_df = pd.read_csv('lalonde.csv')\n",
    "lalonde_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data, we can easily imagine that the first thing we need to do is split the salary data (_['re78']_) into 2 sets: treated and untreated. This will be useful throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks to be used\n",
    "treated = (lambda x: x.treat == 1)\n",
    "untreated = (lambda x: x.treat == 0)\n",
    "\n",
    "#mask application to the first DF\n",
    "treated_salary = lalonde_df[treated(lalonde_df)]['re78']\n",
    "untreated_salary = lalonde_df[untreated(lalonde_df)]['re78']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that a naive researcher unfamiliar with observational studies would treat the data as a randomized trial, not taking into consideration the hidden correlates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Describing the numbers**\n",
    "\n",
    "We first look at the numbers to see how many subjects we have in each group and to see how the values are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lalonde_df.groupby('treat')['re78'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First insights:\n",
    "\n",
    "- The untreated group has more people and their salaries have a higher mean.\n",
    "- However, the 1st salary quartile is twice higher in the treated group and the maximum salary is 3x higher!\n",
    "- We have that the 2nd and 3rd quartiles are higher in the untreated group. Quartiles are more resistent to outliers, hence indicating that the untreated group is faring better.\n",
    "- Finally, the interquartile distance is larger in the untreated set (because of outliers). We use this measure because it is better to measure _'variance'_. Thus, we can say that the untreated group has a more heterogenous salary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Visualizing the data:**\n",
    "\n",
    "We now plot the _['re78']_ salary data in a histogram (with equal sized bins) to find the distribution of salaries of the two groups. We add weights to be able to look at percentages instead of at the number of people in both groups (not equal, meaning it is not informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "bins = np.linspace(0, max(lalonde_df['re78']), 50)\n",
    "plt.hist(untreated_salary, weights=np.ones(len(untreated_salary))/len(untreated_salary), alpha=.5 , bins=bins)\n",
    "plt.hist(treated_salary, weights=np.ones(len(treated_salary))/len(treated_salary), alpha=.5, bins=bins)\n",
    "plt.title('Histogram showing salary treated and untreated groups')\n",
    "plt.legend(['untreated', 'treated'])\n",
    "plt.xlabel('Yearly salary')\n",
    "plt.ylabel('percentage of subjects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second insights:\n",
    "\n",
    "We see a very similar distribution for both functions in the graph, except for the outliers present in the treated group. We also note that there are relatively more subjects in the untreated group with a salary between 10K and 20K while both groups have a similar ratio of subjects in the <10K section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Boxplot:**\n",
    "\n",
    "We use boxplots to illustrate the above number more concisely using a 5 number summary. Note that we remove outliers as we do not consider them to be representative of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_by_treatment(untreated_salary, treated_salary):\n",
    "    \"\"\"draws boxplot of distribution of salary \"\"\"\n",
    "    plt.boxplot([untreated_salary, treated_salary], labels=['untreated', 'treated'], showfliers=False)\n",
    "    plt.title('Distribution of salary by treatment')\n",
    "    plt.ylabel('Salary')\n",
    "    plt.show()\n",
    "\n",
    "outcome_by_treatment(untreated_salary, treated_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "\n",
    "If the treatment was effective, we should have noticed that the people in the treated group were more sucessful on average as they were placed in program (whereas for the untreated group, they were left to fend for themselves).\n",
    "\n",
    "By merging the insights of his 3 steps analysis, the researcher can conclude that **the treatment shows no effect**. The salary distributions are similar in both groups, indicating that the treatment isn't effective.\n",
    "\n",
    "Additionally, the treated group has a lower salary in average (except for the handful of lucky people who find a good job) which is shown by the boxplot: the whiskers extend higher in the untreated group and the median and lower wisker are situated higher up. Since the difference is somewhat small, this may just be due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A closer look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing a simplistic analysis of the data where we ignored underlying factors (such as race and education) that could influence the outcome, we start looking at the whole table assuming that the other features have an impact on _['re78']_.\n",
    "\n",
    "Note that we split our analysis into **categorical** and **interval** data (before determining the correlation between all variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Categorical data :**\n",
    "\n",
    "We can study the categorical data (race, degree and mariage) using their percentages in each population (as the treated and untreated groups have different sizes). To do this, we will simply use the mean of the values because averaging 0s and 1s gives us the percentage of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['black', 'hispan', 'married', 'nodegree']\n",
    "percentages = lalonde_df.groupby('treat')[categories].mean()\n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Race ratios:\n",
    "\n",
    "We will start with race. As we do not have numbers for white participants, we substract the number of black and hispanic participants from the total of each treatment. This is possible because there is no overlap between the _['black']_ and _['hispan']_ categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "black_u, black_t = percentages['black']\n",
    "hispan_u, hispan_t = percentages['hispan']\n",
    "white_u, white_t = (1 - black_u - hispan_u, 1 - black_t - hispan_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_race_rates = [black_u, hispan_u, white_u]\n",
    "t_race_rates = [black_t, hispan_t, white_t]\n",
    "race_labels = 'Black', 'Hispanic', 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_race_rates, t_race_rates, race_labels, 'Racial groups in percent by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are significantly more black subjects in the treated group than in the untreated group. We also note that there are more hispanics in the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Degree ratios:\n",
    "\n",
    "To have a better understanding of the difference of salaries, we also need to look at the level of education of  participants in each treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree_u, degree_t = percentages['nodegree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_degree_rates = [degree_u, 1 - degree_u]\n",
    "t_degree_rates = [degree_t, 1 - degree_t]\n",
    "degree_labels = 'Degree', 'No degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_degree_rates, t_degree_rates, degree_labels, 'Percentage of individuals with a degree, by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the population of treated group is less educated (there is over 10% more people with no degree in the treated set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Marriage ratios:\n",
    "Finally, we analyze our last feature: the rate of married people among both groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "married_u, married_t = percentages['married']\n",
    "not_married_u, not_married_t = (1 - married_u, 1 - married_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_marriage_rates = [married_u, not_married_u]\n",
    "t_marriage_rates = [married_t, not_married_t]\n",
    "mariage_labels = ['Married', 'Not married']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_marriage_rates, t_marriage_rates, mariage_labels, 'Percentage of married individuals by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note once again less married people in the treated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Unemployment ratios:\n",
    "\n",
    "Even though salaries are not categories but intervals, it is important to compare unemployment rates between both groups (which we define as categories: _employed_ and _unemployed_). To get better insights, we plot the evolution of this rate through the years by displaying _['re74']_ and _['re75']_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaries = ['re74', 're75']\n",
    "cat_salaries = lalonde_df.copy()\n",
    "unemployed_labels = 'Employed', 'Unemployed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We draw a boxplot for each column\n",
    "for sal in salaries:\n",
    "    #We classify the data following : employed = 1 and unemployed = 0\n",
    "    cat_salaries[sal] = cat_salaries[sal].map(lambda x : 0 if x == 0 else 1)\n",
    "    u_employed, t_employed = cat_salaries.groupby('treat')[sal].mean()\n",
    "    drawPies([1-u_employed, u_employed],[1-t_employed, t_employed], \n",
    "             unemployed_labels, 'Unemployment rates by treatment in 19'+sal[-2:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the assumption that both groups are balanced before treatment is also wrong for unemployment as we find much more unemployed people in the treated group than in the untreated group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the categorical data, we find that the underlying factors are not similar at all among both groups (the treated group is significantly more black, less educated, less employed and less married). All these factors influence employment and should be taken into consideration.\n",
    "\n",
    "These factors influence salary in the following ways:\n",
    "- Due to racial inequality (especially given the period, the _1970s_), non-white people are more likely to work in worse paying jobs and/or be underpayed.\n",
    "- Better education gets better jobs.\n",
    "- People who already had jobs in 1974/5 are more likely to still have a job in 1978 (and may even have had a raise).\n",
    "- Marriage is an indicator of stability, which may influence job prospects. People often get married when they have a stable job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Interval data :**\n",
    "\n",
    "We now turn to non binary data and the their distribution to get more insights on the data. To do this, we first draw a boxplot and a relative fequency histogram for all variables.\n",
    "\n",
    "_Note that we remove outliers from the box plot as we care more about the general distibution of values in the set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "intervals = ['age', 'educ', 're74', 're75']\n",
    "interval_plots(lalonde_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we see that:\n",
    "- Salaries are very unbalanced between the groups: the treatment group earns much less than the untreated group.\n",
    "- The age distribution is different as the treated group is a bit younger (a lot of individuals are in their _20s_).\n",
    "- Overall, the education level is similar. However, there are more well-educated people in the untreated group; we also note that the number of years of education does not indicate the acquirement of a degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Evolution:\n",
    "\n",
    "Even though it is useful to plot the salaries through the years, it is much more useful to understand how the salary of each participant changes. It is especially interesting to see how the outliers in each year are connected. To do so, we visualize our data using a parallel plot (**orange** represents the treated group while **blue** represents the untreated group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "parallel_coordinates(lalonde_df[untreated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Blue', alpha=0.5)\n",
    "parplot = parallel_coordinates(lalonde_df[treated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Orange' , alpha=0.7)\n",
    "parplot.legend_.remove()\n",
    "plt.title('Salary over time for each participant')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Annualy Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plots, we can that:\n",
    "- The treated group started with a lower salary (the bracket of salaries up to 15K is all blue).\n",
    "- 1975 was a \"bad year\" for everybody (there is an indent in the plot).\n",
    "- The outliers are partially people who were already well payed in 1974 and partialy people who _\"made it\"_.\n",
    "- Most members of the treated group have seen there salaries go up between 1975 and 1978. We also see a slight upwards movement for the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  b. Salary and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed that categorical features influenced the salary, we try to see to what extent our hypothesis holds.\n",
    "\n",
    "**Plotting by race:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "white = (lalonde_df['black'] == 0) & (lalonde_df['hispan'] == 0)\n",
    "years = ['re74', 're75', 're78']\n",
    "\n",
    "for year in years:\n",
    "    plt.boxplot([lalonde_df[white][year], lalonde_df[lalonde_df['black'] == 1][year],\n",
    "                 lalonde_df[lalonde_df['hispan'] == 1][year]], \n",
    "                labels=['white', 'black', 'hispanic'])\n",
    "    plt.title('salary distribution by race in 19'+year[-2:])\n",
    "    plt.ylabel('annual earnings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that :\n",
    "- There is a racial discrepancy in salary\n",
    "- The outliers are all black individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by martial status and degree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    #marriage\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title('single vs married salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='married', y=year, hue='treat')\n",
    "    plt.ylabel('salary')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks(range(2),('singe', 'married'))\n",
    "    \n",
    "    #degree\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title('degree vs nodegree salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='nodegree', y=year, hue='treat')\n",
    "    plt.xticks(range(2),('degree', 'no degree'))\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "- No matter the treatment or the year, married people earn more than single people and people with degrees make more money that people with no degree.\n",
    "- Post-treatment (year 1978) the intra group differences between treated and untreated are the smallest out of all years, but the difference between groups – single & married, degree & no degree– is still visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by age**\n",
    "\n",
    "\n",
    "It is well known that age influences a person's prospects at finding a job but also influence their potential salary. Thus, we map the salary by age (and treatment) for the 3 observed years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    sns.factorplot(data=lalonde_df, x='age', y=year, hue='treat',aspect=4, size=3)\n",
    "    plt.title('salary by age and treatment in 19'+year[-2:])\n",
    "    plt.yticks(np.linspace(0, 40000, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- Pre-treatment, the treated group makes less that the untreated group.\n",
    "- Post-treatment, young people in the treated group easily catch up on people from the untreated group.\n",
    "- The treatment seems to have an effect (in general, people in the treated group catch up, or at least find employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the interval data, and more specificaly at the salaries of participants, we can say that the underlying feature (race, education, marital status) influence the salary. However, our two groups are not balanced which interferes with our first analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Data correlation:**\n",
    "\n",
    "After working on each value alone, we want to understand how each value is (linearly) linked to others looking at each pair of features. To do this, we draw as pairplot as correlation alone does not give us any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_df[['treat', 're78']+intervals], markers='+', hue='treat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot does not tell us a lot other than the fact that we do not see any linear dependence. Thus, we do not spend more time on this part of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A propensity score model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, our naive analysis was based on the false assumption that the distribution was fair in both sets (which we determined was completely false). Thus, it is necessary to create fair sets for our observational study, which is what we do by calculating the propensity score (based on the underlying factors before treatment: _['age', 'educ', 'hispan', 'black', 'nodegree', 're74', 're75']_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_table = lalonde_df.copy()\n",
    "X = prop_table.iloc[:, 2:-1] #input: underlying features\n",
    "y = np.ravel(prop_table.iloc[:, 1:2]) #output: treatment classification\n",
    "print('First elements of Y :\\n', y[0:5],'\\nFirst elements of X :\\n', X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X, y)\n",
    "print('Accuracy of prediction: ', logistic.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example of prediction : \", logistic.predict(X[0:6]), ' reality :', y[0:6])\n",
    "print('Example of prediction estimates : \\n', logistic.predict_proba(X[0:6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the propensity score as a new column. We can interpret this scores as the \"probability of being a treated subject\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop_table['propensity_scores'] = pd.Series(logistic.predict_proba(X)[:,1])\n",
    "prop_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balancing the dataset via matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Solving the bipartite graph problem:**\n",
    "\n",
    "Using the propensity scores we just determined, we try to find a matching to interpret our data. This is nothing more than matching a bipartite graph to get a balanced set. Thus, we turn to _**networkx**_, a Python package which provides matching functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our solution is to create a graph where the _ids_ are the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "B.add_nodes_from(prop_table['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we add (weighted) edges between each treated and untreated subject. The weight of each edge correponds to the (absolute) difference between the nodes.\n",
    "\n",
    "_Note that we use '-x' to transform our minimization problem into a maximum problem to be able to use the **networkx** functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for row_i in prop_table[treated(prop_table)].iterrows():\n",
    "    for row_j in prop_table[untreated(prop_table)].iterrows():\n",
    "        B.add_edge(row_i[1]['id'],row_j[1]['id'], \n",
    "                   weight= 1 - np.abs(row_i[1].propensity_scores - row_j[1].propensity_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we find the matching using a provided function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matching_dict = nx.max_weight_matching(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the number of matched subjects to be sure the method works indeed. We also display example matches to understand the form of the data.\n",
    "\n",
    "_Note: we divide the length of the table by 2 as each pair is displayed twice._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = prop_table.copy()[prop_table['id'].isin(matching_dict)]\n",
    "print('We have : ', len(matched)/2, ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example matches:')\n",
    "list(matching_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Looking at the salary:**\n",
    "\n",
    "Now that our sets make more sense, we compare the outcome _['re78']_ of the treated and untreated groups using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(data=matched, x='treat', y='re78')\n",
    "plt.xticks(range(2), ('untreated', 'treated'))\n",
    "plt.title('Salary in 1978')\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data=matched, x='treat', y='re78',  showfliers=False)\n",
    "plt.xticks(range(2), ('untreated', 'treated'))\n",
    "plt.title('Salary in 1978 without outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we now see that the treated group's salary distribution in 1978 is slightly higher than that of the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Looking at the feature distribution:**\n",
    "\n",
    "The last part of this exercise is dedicated to analyzing the features just like we did in __Exercise 1.02__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_percentages = matched.groupby('treat')[categories].mean()\n",
    "matched_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our categorical data, we immediately see that the distribution of the features is skewed. Even though the racial distribution is the most blatant (almost 40% more blacks in the treated group), the other feature also differ quite consequently (from 2% to around 8%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_plots(matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at the interval data, we see that is much more balanced than it was before, especially the education level of participants of both groups and their salary in 1975."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Balancing the groups further\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature distribution following our propensity score matching, we can still see many discrepancies starting with the high ratio of black people remaining in the treated group comparing to the ratio in the untreated group. Additionally, we still have outliers in the treated group. This clearly means that our dataset is not sufficiently balanced yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Merging the data:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our balancing problem is to merge the DataFrames to work more easily with the data. We display the head of the new DataFrame for clarity (and display the number of matched subjects to make sure our matching makes sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched['match'] = matched['id'].map(matching_dict)\n",
    "balanced_match = matched[treated(matched)].merge(matched[untreated(matched)], left_on='id', right_on='match')\n",
    "balanced_match['difference'] = abs(balanced_match['propensity_scores_x'] - balanced_match['propensity_scores_y'])\n",
    "print('We have : ', len(balanced_match), ' matched subjects')\n",
    "balanced_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the percentages of each feature in both groups to determine the problematic features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Matching by race:**\n",
    "\n",
    "As expected, the first improvement we need to make has to do with race. To do this, we remove mismatched black people (meaning black people who are matched to another race, either white or hispanic). It is also important to monitor the evolution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_bool = (balanced_match['black_x'] == 1) & (balanced_match['black_y'] == 0)\n",
    "balanced_match = balanced_match.drop(balanced_match[race_bool].index)\n",
    "print('We have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Matching by marriage:**\n",
    "\n",
    "When looking at the new dataset, we see a clear difference in the rate of married people between the untreated and the treated group. This is consistant with what we noticed earlier when looking at the data. Thus, it is very important to remove mismatched married people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_bool = (balanced_match['married_x'] == 1) & (balanced_match['married_y'] == 0)\n",
    "balanced_match = balanced_match.drop(balanced_match[marriage_bool].index)\n",
    "print('We have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all features are similar (except for a low difference in the rate of hispanics across both groups). However, we deem the categorical data of our dataset to be balanced enough for the matching to make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iv - Looking at intervals and outliers:**\n",
    "\n",
    "Now that we know our categorical data is balanced, we need to make sure the interval data is still constistent across our groups. However, we still need to perform an important task for the data to be meaningful: we need to remove the outliers (which create a discrepancy on the mean of our data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balanced_interval(df):\n",
    "    df1 = df.iloc[:,:11]\n",
    "    df2 = df.iloc[:, 13:-3]\n",
    "    df2.columns = lalonde_df.columns\n",
    "    df1.columns = lalonde_df.columns\n",
    "    balanced_df = pd.concat([df1, df2])\n",
    "    interval_plots(balanced_df)\n",
    "    \n",
    "balanced_match = balanced_match.drop(balanced_match[balanced_match.re78_x > 30000].index)\n",
    "plot_balanced_interval(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the (more robust) statistics of our interval data, we see very similar distributions over almost features, the age being the main difference between both sets. Once again, we assume this difference to be of minor significance, allowing us to use the dataset for our analysis as we can finally compare people with similar features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that we compare (almost) perfectly matched groups, we only need to look at the distribution of _['re78']_, the outcome we wanted to analyze all along. To interpret our data, we use a 5 number summary (along with its visual representation, our faithful boxplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat([balanced_match.re78_y.describe(),balanced_match.re78_x.describe()], axis=1)\n",
    "stats.columns = ['untreated', 'treated']\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_by_treatment(balanced_match['re78_y'], balanced_match['re78_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of having a higher mean, the quartiles of the treated population are all superior to those of the untreated population. Moreover, the median is significantly higher in the treated group, and so is the maximum salary.\n",
    "\n",
    "The treated group makes a mean of 31% as can be calculated using this formula:\n",
    "\n",
    "$$(6489.919437 - 4944.548418) / 4944.548418 *100 = 31.2540375\\%$$\n",
    "\n",
    "Thus, considering the graph and the numbers, it is clear that **the treatment has a benefic impact** on people.\n",
    "\n",
    "The difference between the naive analysis and our final observation shows the significance of performing the analysis in a way to take into consideration correlates. In this case we this this by the matching we performed on both groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Applied ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this exercise is to build a text classifier. We will first process the data before building the text classifier _per se_ by training it and finally analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transforming the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the data we need to work with. \n",
    "\n",
    "Not that we **remove the headers, footers and quotes**, as suggested in the provided [sklearn tutorial](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html). This allows us to work with more realistic data (which means we do not have access to the metadata). As we will show in Exercise 2.03, this significantly decreases our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data we need to use the vectorizer on. Remove metadata as proposed by sci-kit tutorial\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_with_header = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the TF-IDF matrix of our dataset using a vectorizer. Note that we did not use the **sklearn.datasets.fetch_20newsgroups_vectorized** function which already returns the TF-IDF features as it would defeat the purpose of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(newsgroups_all.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was our understanding from the question that we needed to use all the data provided by sklearn instead of using only the subsets, we created our own testing and validation subsets. We created both sets using a **random_state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate the training set\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_all.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "# Get the testing and validation sets\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training the classifier\n",
    "\n",
    "Now that we have our data (and most importantly our training set), we need to train a random forest. To do this, we  use the RandomForestClassifier as it allows us to use the parameters we have seen in the class. Thus, the main problem is setting our 2 parameters : *max_depth* and *n_estimators*. To get a first idea on how the classifier works, we use 100 trees and a depth of 25 (standard values given in class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find estimators and depth first.\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=25)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)\n",
    "metrics.f1_score(y_valid, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the validation set to evaluate the performance of this first version and use 2 measures to quantify it : the F1 score and the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ',metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the predictions are not satisfying (as expected), we fine tune our model using the validation set. We tried using skikit's **GridSearchSV** function but it did not give any good results (the best parameters were the highest ones and yet, the results were poor). Thus, we decided to implement our own grid search using a double for loop even though the computation is very heavy and takes as much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(X_train, y_train, X_valid, y_valid, range_estimator, range_depth):\n",
    "    \"\"\"Implements grid search, goes over range_estimator and range_depth, returns best parameter in the ranges\n",
    "    X_train: set to train on\n",
    "    y_train: true values training\n",
    "    X_valid: set to test on\n",
    "    y_valid: true values for testing\n",
    "    range_estimator: range to go over for estimator\n",
    "    range_depth: range to go over for depth\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i in range_estimator:\n",
    "        for j in range_depth:\n",
    "            clf = RandomForestClassifier(n_estimators=j, max_depth=i, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_valid)\n",
    "            pred_result = metrics.accuracy_score(y_valid, pred)\n",
    "            print(i,\" ; \", j)\n",
    "            rows.append([i, j, pred_result])\n",
    "    columns=['Depth', 'Estimators', 'Prediction']\n",
    "    all_predictions = pd.DataFrame(rows, columns=columns)\n",
    "    all_predictions = all_predictions.sort_values(by=['Prediction'], ascending=False)\n",
    "    return all_predictions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a good fit over a large number of values takes a lot of time to compute (computations take the whole day). You will find the code to compute the prediction which you can run (at your own risk!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_predictions = GridSearch(X_train, y_train, X_valid, y_valid, range(30, 160, 30), range(300, 1100, 200))\n",
    "#all_predictions.to_pickle(\"all_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved the results in a pickle file so that you would not have to run the function. We display below the 10 best predictions to be able to analyze the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.read_pickle(\"all_predictions.pkl\")\n",
    "all_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the estimators and the depth along the accuracy to understand the link between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.suptitle('Depth, Estimator and Precision')\n",
    "plt.subplot(2,2,1)\n",
    "plt.ylabel('precision accuracy')\n",
    "plt.scatter(all_predictions['Depth'], all_predictions['Prediction'])\n",
    "plt.xlabel('depth')\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "plt.xlabel('number of estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph above is not very informative, we visualize the data in 3D to see the relationship between the 3 variables (and not simply pairwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(all_predictions['Depth'], all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "ax.set_title('3D plot of Estimators, Depth and Precision')\n",
    "ax.set_xlabel('depth')\n",
    "ax.set_ylabel('number of estimators')\n",
    "ax.set_zlabel('prediction accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have the best results when *n_estimators* is set around 700 and *max_depth* is set around 130."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What striked us is that most tutorials on the Internet show 80+% accuracy using Random Forest Classifiers as well while we cannot get past 68%. As explained before, this is the result of taking out all metadata. Even though these predictions are more realistic, we will see in **Exercise 2.03** how this model compares with a model with metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined the best results possible of our model, we construct a confusion matrix (and display it using a heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "df.index = newsgroups_all.target_names\n",
    "df.columns = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the well-classified values (true positives) on the diagonal and notice that some classes are predicted more accurately than others. For example, our classifier classifies **sport.hockey** very well but has great trouble classifying **talk.religious.misc** correctly. This result is consistent with the mixups we notice (false negatives & false positives) which happen most frequently within similar topics (namely **religion.misc** and **religion.christian**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important attribute of the random forest to understand is the `feature_importances_` (most significant features). Without much surprise, we see keywords such as **car** or **god** which clearly indicate a topic. For example, a text containing **god** will most likely be religious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second list, we see the least indicative (and yet still indicative features). These are very cryptic as they probably only show up once, yet strongly indicate the type of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the importance of each feature, we want to understand the relationship between the (200) most important features. As expected, the importance of features decreases slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature importance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to know how much features are really important (and how much are not as indicative). As we have a lot of features, we are forced to use a log scale to see relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "#note the log scale!\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see very easily that most features are not used for the classification(aggregation on the left of the graph showing very little importance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prediction with labels\n",
    "\n",
    "After training our classifier, we want to know how much better it fares by keeping the labels in the dataset. In order to do a relevant analysis, we assume that both sets are similar (which is why we use the same preprocessing steps and the same estimator values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(newsgroups_with_header.data)\n",
    "\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_with_header.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find immediately that the results are much better according to both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we display the confusion matrix to see exactly what are the best classified classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "df.columns = newsgroups_all.target_names\n",
    "df.index = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the previous confusion matrix, we have a lot more well-classified values and less mixups. However, we notice that the hardest classes to label are the same (namely classes having to do with religion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we inspect the `feature_importances_` attribute of our random forest for this classifier. The significant features make sense (even though we note the presence of linking words, which are not informative at all). On the other hand, the unsignificant features are even more esoterical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most significant features\n",
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst still positive \n",
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the relationship between the most relevant features and notice that, unlike on the previous graph, the slope of the function is a lot steeper. This means that only a few features are very relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature impotance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To comfort ourselves in this idea, we plot a histogram to see how many features we have in each bin. We see that the feature distributon does not change a lot by adding the metadata even though unsignificant and significant features are more separated than before. We also have that the more significant values are even more significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
