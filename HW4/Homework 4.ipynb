{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Steps\n",
    "\n",
    "We start the homework by importing the (many!) needed libraries and define functions that will help us later in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the same libraries as in the \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, GridSearchCV, PredefinedSplit\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function allows us to draw custom charts (and display them inline to be able to get useful insights). This will be used a lot throughout Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use this a lot :D\n",
    "def drawPies(u_rates, t_rates, labels, supertitle):\n",
    "    \"\"\"draws pretty comparative pie charts\n",
    "    u_rates : rates for untreated group\n",
    "    t_rates : rates for treated group\n",
    "    lables: labels for values in rates\n",
    "    supertitle: title of chart\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    fig.suptitle(supertitle)\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.pie(u_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"untreated group\")\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.pie(t_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"treated group\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function we define is used to compare the interval variables (cf Exercises 1.02 and 1.04) of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_plots(df):\n",
    "    \"\"\"constructs boxplot and relative frequency histogram for data frame\n",
    "    df: dataframe to be analyzed\n",
    "    \"\"\"\n",
    "    #for each column draw a Boxplot\n",
    "    for col in intervals:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        treated_ = df[treated(df)][col]\n",
    "        untreated_ = df[untreated(df)][col]\n",
    "\n",
    "        #boxplot\n",
    "        plt.subplot(2,2,1)\n",
    "        plt.title(\"Boxplot of \" + col)\n",
    "        plt.boxplot([untreated_, treated_], \n",
    "                    labels=['untreated', 'treated'], showfliers=False)\n",
    "        plt.ylabel(col)\n",
    "\n",
    "        #histogram\n",
    "        plt.subplot(2,2,2)\n",
    "        bins = np.linspace(min(df[col]), max(lalonde_df[col]), 50)\n",
    "        plt.title(\"Relative frequency histogram of \" + col)\n",
    "        plt.ylabel('percentage')\n",
    "        plt.xlabel(col)\n",
    "        plt.hist(untreated_, weights=np.ones(len(untreated_))/len(untreated_), alpha=.5 , bins=bins)\n",
    "        plt.hist(treated_, weights=np.ones(len(treated_))/len(treated_), alpha=.5, bins=bins)\n",
    "        plt.legend(['untreated', 'treated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function is used in exercise 1.05 in order to compare the probabilities of categorical data between both groups (treated and untreated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups(table) :\n",
    "    \"\"\"\n",
    "    Compares groups in merged dataframe\n",
    "    table : dataframe to compare treated and untreated in\n",
    "    \"\"\"\n",
    "    columns = ['untreated', 'treated']\n",
    "    index = ['black', 'hisp', 'married', 'no_degree']\n",
    "    result = pd.DataFrame(columns=columns, index=index)\n",
    "    result['untreated']['black'] = table['black_y'].mean()\n",
    "    result['untreated']['hisp'] = table['hispan_y'].mean()\n",
    "    result['untreated']['married'] = table['married_y'].mean()\n",
    "    result['untreated']['no_degree'] = table['nodegree_y'].mean()\n",
    "    result['treated']['black'] = table['black_x'].mean()\n",
    "    result['treated']['hisp'] = table['hispan_x'].mean()\n",
    "    result['treated']['married'] = table['married_x'].mean()\n",
    "    result['treated']['no_degree'] = table['nodegree_x'].mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Propensity Score Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this exercise is to analyze a dataset first without any real knowledge (naive analysis) and then through multiple processing steps to understand the data further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the data (and displaying it to understand the format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lalonde_df = pd.read_csv('lalonde.csv')\n",
    "lalonde_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data, we can easily imagine that the first thing we need to do is split the salary data (_['re78']_) into 2 sets: treated and untreated. This will be useful throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks to be used\n",
    "treated = (lambda x: x.treat == 1)\n",
    "untreated = (lambda x: x.treat == 0)\n",
    "\n",
    "#mask application to the first DF\n",
    "treated_salary = lalonde_df[treated(lalonde_df)]['re78']\n",
    "untreated_salary = lalonde_df[untreated(lalonde_df)]['re78']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that a naive researcher unfamiliar with observational studies would treat the data as a randomized trial, not taking into consideration the hidden correlates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Describing the numbers**\n",
    "\n",
    "We first look at the numbers to see how many subjects we have in each group and to see how the values are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lalonde_df.groupby('treat')['re78'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First insights:\n",
    "\n",
    "- The untreated group has more people and their salaries have a higher mean.\n",
    "- However, the 1st salary quartile is twice higher in the treated group and the maximum salary is 3x higher!\n",
    "- We have that the 2nd and 3rd quartiles are higher in the untreated group. Quartiles are more resistent to outliers, hence indicating that the untreated group is faring better.\n",
    "- Finally, the interquartile distance is larger in the untreated set (because of outliers). We use this measure because it is better to measure _'variance'_. Thus, we can say that the untreated group has a more heterogenous salary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Visualizing the data:**\n",
    "\n",
    "We now plot the _['re78']_ salary data in a histogram (with equal sized bins) to find the distribution of salaries of the two groups. We add weights to be able to look at percentages instead of at the number of people in both groups (not equal, meaning it is not informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "bins = np.linspace(0, max(lalonde_df['re78']), 50)\n",
    "plt.hist(untreated_salary, weights=np.ones(len(untreated_salary))/len(untreated_salary), alpha=.5 , bins=bins)\n",
    "plt.hist(treated_salary, weights=np.ones(len(treated_salary))/len(treated_salary), alpha=.5, bins=bins)\n",
    "plt.title('Histogram showing salary treated and untreated groups')\n",
    "plt.legend(['untreated', 'treated'])\n",
    "plt.xlabel('Yearly salary')\n",
    "plt.ylabel('percentage of subjects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second insights:\n",
    "\n",
    "We see a very similar distribution for both functions in the graph, except for the outliers present in the treated group. We also note that there are relatively more subjects in the untreated group with a salary between 10K and 20K while both groups have a similar ratio of subjects in the <10K section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Boxplot:**\n",
    "\n",
    "We use boxplots to illustrate the above number more concisely using a 5 number summary. Note that we remove outliers as we do not consider them to be representative of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_by_treatment(untreated_salary, treated_salary):\n",
    "    \"\"\"draws boxplot of distribution of salary \"\"\"\n",
    "    plt.boxplot([untreated_salary, treated_salary], labels=['untreated', 'treated'], showfliers=False)\n",
    "    plt.title('Distribution of salary by treatment')\n",
    "    plt.ylabel('Salary')\n",
    "    plt.show()\n",
    "\n",
    "outcome_by_treatment(untreated_salary, treated_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "\n",
    "If the treatment was effective, we should have noticed that the people in the treated group were more sucessful on average as they were placed in program (whereas for the untreated group, they were left to fend for themselves).\n",
    "\n",
    "By merging the insights of his 3 steps analysis, the researcher can conclude that **the treatment shows no effect**. The salary distributions are similar in both groups, indicating that the treatment isn't effective.\n",
    "\n",
    "Additionally, the treated group has a lower salary in average (except for the handful of lucky people who find a good job) which is shown by the boxplot: the whiskers extend higher in the untreated group and the median and lower wisker are situated higher up. Since the difference is somewhat small, this may just be due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A closer look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing a simplistic analysis of the data where we ignored underlying factors (such as race and education) that could influence the outcome, we start looking at the whole table assuming that the other features have an impact on _['re78']_.\n",
    "\n",
    "Note that we split our analysis into **categorical** and **interval** data (before determining the correlation between all variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Categorical data :**\n",
    "\n",
    "We can study the categorical data (race, degree and mariage) using their percentages in each population (as the treated and untreated groups have different sizes). To do this, we will simply use the mean of the values because averaging 0s and 1s gives us the percentage of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['black', 'hispan', 'married', 'nodegree']\n",
    "percentages = lalonde_df.groupby('treat')[categories].mean()\n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Race ratios:\n",
    "\n",
    "We will start with race. As we do not have numbers for white participants, we substract the number of black and hispanic participants from the total of each treatment. This is possible because there is no overlap between the _['black']_ and _['hispan']_ categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_u, black_t = percentages['black']\n",
    "hispan_u, hispan_t = percentages['hispan']\n",
    "white_u, white_t = (1 - black_u - hispan_u, 1 - black_t - hispan_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_race_rates = [black_u, hispan_u, white_u]\n",
    "t_race_rates = [black_t, hispan_t, white_t]\n",
    "race_labels = 'Black', 'Hispanic', 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_race_rates, t_race_rates, race_labels, 'Racial groups in percent by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are significantly more black subjects in the treated group than in the untreated group. We also note that there are more hispanics in the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Degree ratios:\n",
    "\n",
    "To have a better understanding of the difference of salaries, we also need to look at the level of education of  participants in each treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_u, degree_t = percentages['nodegree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_degree_rates = [degree_u, 1 - degree_u]\n",
    "t_degree_rates = [degree_t, 1 - degree_t]\n",
    "degree_labels = 'Degree', 'No degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_degree_rates, t_degree_rates, degree_labels, 'Percentage of individuals with a degree, by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the population of treated group is less educated (there is over 10% more people with no degree in the treated set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Marriage ratios:\n",
    "Finally, we analyze our last feature: the rate of married people among both groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "married_u, married_t = percentages['married']\n",
    "not_married_u, not_married_t = (1 - married_u, 1 - married_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_marriage_rates = [married_u, not_married_u]\n",
    "t_marriage_rates = [married_t, not_married_t]\n",
    "mariage_labels = ['Married', 'Not married']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_marriage_rates, t_marriage_rates, mariage_labels, 'Percentage of married individuals by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note once again less married people in the treated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Unemployment ratios:\n",
    "\n",
    "Even though salaries are not categories but intervals, it is important to compare unemployment rates between both groups (which we define as categories: _employed_ and _unemployed_). To get better insights, we plot the evolution of this rate through the years by displaying _['re74']_ and _['re75']_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = ['re74', 're75']\n",
    "cat_salaries = lalonde_df.copy()\n",
    "unemployed_labels = 'Employed', 'Unemployed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We draw a boxplot for each column\n",
    "for sal in salaries:\n",
    "    #We classify the data following : employed = 1 and unemployed = 0\n",
    "    cat_salaries[sal] = cat_salaries[sal].map(lambda x : 0 if x == 0 else 1)\n",
    "    u_employed, t_employed = cat_salaries.groupby('treat')[sal].mean()\n",
    "    drawPies([1-u_employed, u_employed],[1-t_employed, t_employed], \n",
    "             unemployed_labels, 'Unemployment rates by treatment in 19'+sal[-2:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the assumption that both groups are balanced before treatment is also wrong for unemployment as we find much more unemployed people in the treated group than in the untreated group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the categorical data, we find that the underlying factors are not similar at all among both groups (the treated group is significantly more black, less educated, less employed and less married). All these factors influence employment and should be taken into consideration.\n",
    "\n",
    "These factors influence salary in the following ways:\n",
    "- Due to racial inequality (especially given the period, the _1970s_), non-white people are more likely to work in worse paying jobs and/or be underpayed.\n",
    "- Better education gets better jobs.\n",
    "- People who already had jobs in 1974/5 are more likely to still have a job in 1978 (and may even have had a raise).\n",
    "- Marriage is an indicator of stability, which may influence job prospects. People often get married when they have a stable job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Interval data :**\n",
    "\n",
    "We now turn to non binary data and the their distribution to get more insights on the data. To do this, we first draw a boxplot and a relative fequency histogram for all variables.\n",
    "\n",
    "_Note that we remove outliers from the box plot as we care more about the general distibution of values in the set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "intervals = ['age', 'educ', 're74', 're75']\n",
    "interval_plots(lalonde_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we see that:\n",
    "- Salaries are very unbalanced between the groups: the treatment group earns much less than the untreated group.\n",
    "- The age distribution is different as the treated group is a bit younger (a lot of individuals are in their _20s_).\n",
    "- Overall, the education level is similar. However, there are more well-educated people in the untreated group; we also note that the number of years of education does not indicate the acquirement of a degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Evolution:\n",
    "\n",
    "Even though it is useful to plot the salaries through the years, it is much more useful to understand how the salary of each participant changes. It is especially interesting to see how the outliers in each year are connected. To do so, we visualize our data using a parallel plot (**orange** represents the treated group while **blue** represents the untreated group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "parallel_coordinates(lalonde_df[untreated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Blue', alpha=0.5)\n",
    "parplot = parallel_coordinates(lalonde_df[treated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Orange' , alpha=0.7)\n",
    "parplot.legend_.remove()\n",
    "plt.title('Salary over time for each participant')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Annualy Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plots, we can that:\n",
    "- The treated group started with a lower salary (the bracket of salaries up to 15K is all blue).\n",
    "- 1975 was a \"bad year\" for everybody (there is an indent in the plot).\n",
    "- The outliers are partially people who were already well payed in 1974 and partialy people who _\"made it\"_.\n",
    "- Most members of the treated group have seen there salaries go up between 1975 and 1978. We also see a slight upwards movement for the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  b. Salary and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed that categorical features influenced the salary, we try to see to what extent our hypothesis holds.\n",
    "\n",
    "**Plotting by race:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "white = (lalonde_df['black'] == 0) & (lalonde_df['hispan'] == 0)\n",
    "years = ['re74', 're75', 're78']\n",
    "\n",
    "for year in years:\n",
    "    plt.boxplot([lalonde_df[white][year], lalonde_df[lalonde_df['black'] == 1][year],\n",
    "                 lalonde_df[lalonde_df['hispan'] == 1][year]], \n",
    "                labels=['white', 'black', 'hispanic'])\n",
    "    plt.title('salary distribution by race in 19'+year[-2:])\n",
    "    plt.ylabel('annual earnings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that :\n",
    "- There is a racial discrepancy in salary\n",
    "- The outliers are all black individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by martial status and degree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    #marriage\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title('single vs married salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='married', y=year, hue='treat')\n",
    "    plt.ylabel('salary')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks(range(2),('singe', 'married'))\n",
    "    \n",
    "    #degree\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title('degree vs nodegree salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='nodegree', y=year, hue='treat')\n",
    "    plt.xticks(range(2),('degree', 'no degree'))\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "- No matter the treatment or the year, married people earn more than single people and people with degrees make more money that people with no degree.\n",
    "- Post-treatment (year 1978) the intra group differences between treated and untreated are the smallest out of all years, but the difference between groups – single & married, degree & no degree– is still visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by age**\n",
    "\n",
    "\n",
    "It is well known that age influences a person's prospects at finding a job but also influence their potential salary. Thus, we map the salary by age (and treatment) for the 3 observed years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    sns.factorplot(data=lalonde_df, x='age', y=year, hue='treat',aspect=4, size=3)\n",
    "    plt.title('salary by age and treatment in 19'+year[-2:])\n",
    "    plt.yticks(np.linspace(0, 40000, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- Pre-treatment, the treated group makes less that the untreated group.\n",
    "- Post-treatment, young people in the treated group easily catch up on people from the untreated group.\n",
    "- The treatment seems to have an effect (in general, people in the treated group catch up, or at least find employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the interval data, and more specificaly at the salaries of participants, we can say that the underlying feature (race, education, marital status) influence the salary. However, our two groups are not balanced which interferes with our first analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Data correlation:**\n",
    "\n",
    "After working on each value alone, we want to understand how each value is (linearly) linked to others looking at each pair of features. To do this, we draw as pairplot as correlation alone does not give us any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_df[['treat', 're78']+intervals], markers='+', hue='treat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot does not tell us a lot other than the fact that we do not see any linear dependence. Thus, we do not spend more time on this part of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A propensity score model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, our naive analysis was based on the false assumption that the distribution was fair in both sets (which we determined was completely false). Thus, it is necessary to create fair sets for our observational study, which is what we do by calculating the propensity score (based on the underlying factors before treatment: _['age', 'educ', 'hispan', 'black', 'nodegree', 're74', 're75']_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_table = lalonde_df.copy()\n",
    "X = prop_table.iloc[:, 2:-1] #input: underlying features\n",
    "y = np.ravel(prop_table.iloc[:, 1:2]) #output: treatment classification\n",
    "print('First elements of Y :\\n', y[0:5],'\\nFirst elements of X :\\n', X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X, y)\n",
    "print('Accuracy of prediction: ', logistic.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example of prediction : \", logistic.predict(X[0:6]), ' reality :', y[0:6])\n",
    "print('Example of prediction estimates : \\n', logistic.predict_proba(X[0:6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the propensity score as a new column. We can interpret this scores as the \"probability of being a treated subject\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop_table['propensity_scores'] = pd.Series(logistic.predict_proba(X)[:,1])\n",
    "prop_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balancing the dataset via matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Solving the bipartite graph problem:**\n",
    "\n",
    "Using the propensity scores we just determined, we try to find a matching to interpret our data. This is nothing more than matching a bipartite graph to get a balanced set. Thus, we turn to _**networkx**_, a Python package which provides matching functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our solution is to create a graph where the _ids_ are the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "B.add_nodes_from(prop_table['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we add (weighted) edges between each treated and untreated subject. The weight of each edge correponds to the (absolute) difference between the nodes.\n",
    "\n",
    "_Note that we use '-x' to transform our minimization problem into a maximum problem to be able to use the **networkx** functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for row_i in prop_table[treated(prop_table)].iterrows():\n",
    "    for row_j in prop_table[untreated(prop_table)].iterrows():\n",
    "        B.add_edge(row_i[1]['id'],row_j[1]['id'], \n",
    "                   weight= 1 - np.abs(row_i[1].propensity_scores - row_j[1].propensity_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we find the matching using a provided function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = nx.max_weight_matching(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the number of matched subjects to be sure the method works indeed. We also display example matches to understand the form of the data.\n",
    "\n",
    "_Note: we divide the length of the table by 2 as each pair is displayed twice._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = prop_table.copy()[prop_table['id'].isin(matching_dict)]\n",
    "print('We have : ', len(matched)/2, ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example matches:')\n",
    "list(matching_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Looking at the salary:**\n",
    "\n",
    "Now that our sets make more sense, we compare the outcome _['re78']_ of the treated and untreated groups using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(data=matched, x='treat', y='re78')\n",
    "plt.xticks(range(2), ('untreated', 'treated'))\n",
    "plt.title('Salary in 1978')\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data=matched, x='treat', y='re78',  showfliers=False)\n",
    "plt.xticks(range(2), ('untreated', 'treated'))\n",
    "plt.title('Salary in 1978 without outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we now see that the treated group's salary distribution in 1978 is slightly higher than that of the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Looking at the feature distribution:**\n",
    "\n",
    "The last part of this exercise is dedicated to analyzing the features just like we did in __Exercise 1.02__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_percentages = matched.groupby('treat')[categories].mean()\n",
    "matched_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our categorical data, we immediately see that the distribution of the features is skewed. Even though the racial distribution is the most blatant (almost 40% more blacks in the treated group), the other feature also differ quite consequently (from 2% to around 8%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_plots(matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at the interval data, we see that is much more balanced than it was before, especially the education level of participants of both groups and their salary in 1975."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Balancing the groups further\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature distribution following our propensity score matching, we can still see many discrepancies starting with the high ratio of black people remaining in the treated group comparing to the ratio in the untreated group. Additionally, we still have outliers in the treated group. This clearly means that our dataset is not sufficiently balanced yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Merging the data:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our balancing problem is to merge the DataFrames to work more easily with the data. We display the head of the new DataFrame for clarity (and display the number of matched subjects to make sure our matching makes sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched['match'] = matched['id'].map(matching_dict)\n",
    "balanced_match = matched[treated(matched)].merge(matched[untreated(matched)], left_on='id', right_on='match')\n",
    "balanced_match['difference'] = abs(balanced_match['propensity_scores_x'] - balanced_match['propensity_scores_y'])\n",
    "print('We have : ', len(balanced_match), ' matched subjects')\n",
    "balanced_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the percentages of each feature in both groups to determine the problematic features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Matching by race:**\n",
    "\n",
    "As expected, the first improvement we need to make has to do with race. To do this, we remove mismatched black people (meaning black people who are matched to another race, either white or hispanic). It is also important to monitor the evolution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_bool = (balanced_match['black_x'] == 1) & (balanced_match['black_y'] == 0)\n",
    "balanced_match = balanced_match.drop(balanced_match[race_bool].index)\n",
    "print('We have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Matching by marriage:**\n",
    "\n",
    "When looking at the new dataset, we see a clear difference in the rate of married people between the untreated and the treated group. This is consistant with what we noticed earlier when looking at the data. Thus, it is very important to remove mismatched married people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_bool = (balanced_match['married_x'] == 0) & (balanced_match['married_y'] == 1)\n",
    "balanced_match = balanced_match.drop(balanced_match[marriage_bool].index)\n",
    "print('We have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all features are similar (except for a low difference in the rate of hispanics across both groups). However, we deem the categorical data of our dataset to be balanced enough for the matching to make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iv - Looking at intervals and outliers:**\n",
    "\n",
    "Now that we know our categorical data is balanced, we need to make sure the interval data is still constistent across our groups. However, we still need to perform an important task for the data to be meaningful: we need to remove the outliers (which create a discrepancy on the mean of our data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balanced_interval(df):\n",
    "    df1 = df.iloc[:,:11]\n",
    "    df2 = df.iloc[:, 13:-3]\n",
    "    df2.columns = lalonde_df.columns\n",
    "    df1.columns = lalonde_df.columns\n",
    "    balanced_df = pd.concat([df1, df2])\n",
    "    interval_plots(balanced_df)\n",
    "    \n",
    "balanced_match = balanced_match.drop(balanced_match[balanced_match.re78_x > 30000].index)\n",
    "plot_balanced_interval(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the (more robust) statistics of our interval data, we see very similar distributions over almost features, the age being the main difference between both sets. Once again, we assume this difference to be of minor significance, allowing us to use the dataset for our analysis as we can finally compare people with similar features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that we compare (almost) perfectly matched groups, we only need to look at the distribution of _['re78']_, the outcome we wanted to analyze all along. To interpret our data, we use a 5 number summary (along with its visual representation, our faithful boxplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat([balanced_match.re78_y.describe(),balanced_match.re78_x.describe()], axis=1)\n",
    "stats.columns = ['untreated', 'treated']\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_by_treatment(balanced_match['re78_y'], balanced_match['re78_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of having a higher mean, the quartiles of the treated population are all superior to those of the untreated population. Moreover, the median is significantly higher in the treated group, and so is the maximum salary.\n",
    "\n",
    "The treated group makes a mean of 31% as can be calculated using this formula:\n",
    "\n",
    "$$(6489.919437 - 4944.548418) / 4944.548418 *100 = 31.2540375\\%$$\n",
    "\n",
    "Thus, considering the graph and the numbers, it is clear that **the treatment has a benefic impact** on people.\n",
    "\n",
    "The difference between the naive analysis and our final observation shows the significance of performing the analysis in a way to take into consideration correlates. In this case we this this by the matching we performed on both groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Applied ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we build a text classifier and analyze it's preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transforming the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to compute the TF-IDF features of our dataset, using a vectorizer. As we understood the question, it was not asked to use any of the given datasets from sklearn, but to use all of the data. Thus, we do not use the train and test subsets given to us in sklearn, but will create our own such subsets, adding a validation subset.\n",
    "\n",
    "Also note that we **remove the headers, footers and quotes**, as proposed in the <a href=\"http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\">sklearn tutorial</a> of the dataset, as to have something more realistic and without any of the metadata. \n",
    "This significantly decreases our accuracy, as we show later in section 3.\n",
    "\n",
    "Note also that we did not use the *sklearn.datasets.fetch_20newsgroups_vectorized* function that returns the TF-IDF features directly, as it would defeat the purpose of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data we need to use the vectorizer on. Remove metadata as proposed by sci-kit tutorial\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_with_header = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As asked in the question, before seperating in subsets, we will use the vectorizer on the complete set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors is a sparse matrix\n",
    "X = tfidf.fit_transform(newsgroups_all.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to seperate the dataset into three sets: train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we seperate train from the rest. Random_state given to have a seed.\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_all.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "# then we seperate again to get validation and test seperately\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the classifier\n",
    "\n",
    "Now we need to train a random forest on our training set. For this, we will use the RandomForestClassifier, as it contains the parameters talked about in the exercise. But first, we need to ask ourselves what we want to set the parameters (*max_depth* and *n_estimators*) to.\n",
    "\n",
    "We set the two parameters to get a first idea on what values we will get for the prediction.\n",
    "We use 100 trees and a depth of 25, values that are similar to the ones given in the course.\n",
    "\n",
    "For the predictions, we can't use the training set, as we just trained on it and thus would get very good results regardless of the goodness of fit. So prediction has to be on the validation set.\n",
    "\n",
    "We use two measure the goodness of our system to the data by two measures, F1 score and prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find estimators and depth first.\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=25)\n",
    "clf.fit(vect_train, newsgroups_train)\n",
    "pred = clf.predict(vect_valid)\n",
    "metrics.f1_score(newsgroups_valid, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ',metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, predictions aren't that great.\n",
    "\n",
    "We try to fine tune on the validation set. We first used skikit's GridSearchCV function, but could not find the right parameters to make the function work perfectly. \n",
    "In fact, the best parameters were almost always the highest ones, yet the results of predictions stayed quite poor.\n",
    "\n",
    "Thus, we decided to use a double for loop, implementing the grid search. Even if this type of computation is very heavy and takes a lot more time aswell.\n",
    "\n",
    "Please note that finding a good fit over a large range of values takes a lot of time to compute, as there are a very large numbers of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We made a few tries already to determine which values yield better results.\n",
    "# We have a double for loop. Which is aweful and will take a lot of time, but necessary.\n",
    "def GridSearch(X_train, y_train, X_valid, y_valid, range_estimator, range_depth):\n",
    "    \"\"\"Implements grid search, goes over range_estimator and range_depth, returns best parameter in the ranges\n",
    "    X_train: set to train on\n",
    "    y_train: true values training\n",
    "    X_valid: set to test on\n",
    "    y_valid: true values for testing\n",
    "    range_estimator: range to go over for estimator\n",
    "    range_depth: range to go over for depth\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i in range_estimator: #making sure the depth is not better above 30\n",
    "        for j in range_depth: #step of 100 to not take too much time\n",
    "            clf = RandomForestClassifier(n_estimators=j, max_depth=i, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_valid)\n",
    "            pred_result = metrics.accuracy_score(y_valid, pred)\n",
    "            # uncomment next line to be able to know where computation is at\n",
    "            print(i,\" ; \", j)\n",
    "            rows.append([i, j, pred_result])\n",
    "    # We create a DF to be able to use all this data effectively\n",
    "    columns=['Depth', 'Estimators', 'Prediction']\n",
    "    all_predictions = pd.DataFrame(rows, columns=columns) # we get all the predictions in a dataframe\n",
    "    # we sort by best prediction\n",
    "    all_predictions = all_predictions.sort_values(by=['Prediction'], ascending=False)\n",
    "    # we show the best 10\n",
    "    return all_predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_predictions = GridSearch(X_train, y_train, X_valid, y_valid, range(30, 160, 30), range(300, 1100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously run the loop overnight and saved the findings into a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the pickle. Do not run if we did not make a new pandas.\n",
    "# all_predictions.to_pickle(\"all_predictions.pkl\")\n",
    "# read the pickle.\n",
    "all_predictions = pd.read_pickle(\"all_predictions.pkl\")\n",
    "all_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly visualize the points in the file to get an overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.suptitle('Depth, Estimator and precision accuracy')\n",
    "plt.subplot(2,2,1)\n",
    "plt.ylabel('precision accuracy')\n",
    "plt.scatter(all_predictions['Depth'], all_predictions['Prediction'])\n",
    "plt.xlabel('depth')\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "plt.xlabel('number of estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(all_predictions['Depth'], all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "ax.set_title('3d plot of estimators depth and precision relationship')\n",
    "ax.set_xlabel('depth')\n",
    "ax.set_ylabel('number of estimators')\n",
    "ax.set_zlabel('prediction accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, te best resuts are when *n_estimators* is set around 700 and *max_depth* is set at 130. Note that because we have a bit of randomness, the results are not deterministic.\n",
    "\n",
    "We note that tutorials on the internet show 80% and more accuracy for random forest classifiers, where as we only get 68%.\n",
    "This is because we have taken out all metadata, as asked for by the tutorial on sklearn. Thus, we have more realistic predictions and results. To show this, let us compare predictions with and without metadata in section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a confusion matrix on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "#get confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "#renaming for convenience\n",
    "df.columns = newsgroups_all.target_names\n",
    "df.index = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to read this matrix, lets put it into a DataFrame and add the right column names, then show the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal shows us the true positives. we see that some classes have higher prediction accuracy than others.\n",
    "Our classifier classifies sport.hockey very well but has great trouble classifying talk.religious.misc correctly.\n",
    "\n",
    "Then the mixups (false negatives & false positives) are within similar topics, such as religion.muisc & religion.christian –this is a false negative, the classifier assigned talk.religion.misc but the true lable is talk.religion.misc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the `feature_importances_` attribute of our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most significant features\n",
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not suprising to see keywords such as car or god in this list, as they clearly indicate a topic. A text containing god will more likely be religous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst still positive \n",
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the least indicative still indicative features are very cryptic, they probably only show up in one text, but strongly indicate the type of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at te most relevant features in relation to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature impotance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the first are very relevant, and the the slope of relevancy slowly goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also have an idea of how many features are important or not by plotting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "#note the log scale!\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that very few features are very important, while most are useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prediction with lables\n",
    "\n",
    "We now show how much better the prediction is if we keep the lables in the dataset.\n",
    "\n",
    "We prefrom the same data processing as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors is a sparse matrix\n",
    "X = tfidf.fit_transform(newsgroups_with_header.data)\n",
    "\n",
    "# first we seperate train from the rest. Random_state given to have a seed.\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_with_header.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "# then we seperate again to get validation and test seperately\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the assumption that the estimators on both sets will be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immeditely see that the results are much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "#get confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "#renaming for convenience\n",
    "df.columns = newsgroups_all.target_names\n",
    "df.index = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to read this matrix, lets put it into a DataFrame and add the right column names, then show the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that compared to the previous confusion matrix we have a lot more true positives and less false negatives & false positives.\n",
    "\n",
    "The features that were hard to label before still get labeled incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the `feature_importances_` attribute of our random forest for this classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most significant features\n",
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst still positive \n",
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the unsignificant features are more nonsensical than before and the significant features stay similar, although there is some change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at te most relevant features in relation to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature impotance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the first are very relevant, and the the slope of relevancy is a lot more steep than in the above case.\n",
    "We thus have a very few very relevant features, an less lesser relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also have an idea of how many features are important or not by plotting them in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "#note the og scale!\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the feature importance distributon does not change a lot by adding metadata to the set.\n",
    "Unsignificant and significant features are however more separated compared to the features obtained before and the distribution is sightly shifted to the left."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
