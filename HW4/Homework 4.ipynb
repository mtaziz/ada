{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Steps\n",
    "\n",
    "We start the homework by importing the (many!) needed libraries and define functions that will help us later in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the same libraries as in the \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, GridSearchCV, PredefinedSplit\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function allows us to draw custom charts (and display them inline to be able to get useful insights). This will be used a lot throughout Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use this a lot :D\n",
    "def drawPies(u_rates, t_rates, labels, supertitle):\n",
    "    \"\"\"draws pretty comparative pie charts\n",
    "    u_rates : rates for untreated group\n",
    "    t_rates : rates for treated group\n",
    "    lables: labels for values in rates\n",
    "    supertitle: title of chart\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    fig.suptitle(supertitle)\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.pie(u_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"control group\")\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.pie(t_rates, labels = labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"treated group\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function we define is used to compare the interval variables (cf Exercises 1.02 and 1.04) of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interval_plots(df):\n",
    "    \"\"\"constructs boxplot and relative frequency histogram for data frame\n",
    "    df: dataframe to be analyzed\n",
    "    \"\"\"\n",
    "    #for each column draw a Boxplot\n",
    "    for col in intervals:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        treated_ = df[treated(df)][col]\n",
    "        untreated_ = df[untreated(df)][col]\n",
    "\n",
    "        #boxplot\n",
    "        plt.subplot(2,2,1)\n",
    "        plt.title(\"Boxplot of \" + col)\n",
    "        plt.boxplot([untreated_, treated_], \n",
    "                    labels=['untreated', 'treated'], showfliers=False)\n",
    "        plt.ylabel(col)\n",
    "\n",
    "        #histogram\n",
    "        plt.subplot(2,2,2)\n",
    "        bins = np.linspace(min(df[col]), max(lalonde_df[col]), 50)\n",
    "        plt.title(\"Relative frequency histogram of \" + col)\n",
    "        plt.ylabel('percentage')\n",
    "        plt.xlabel(col)\n",
    "        plt.hist(untreated_, weights=np.ones(len(untreated_))/len(untreated_), alpha=.5 , bins=bins)\n",
    "        plt.hist(treated_, weights=np.ones(len(treated_))/len(treated_), alpha=.5, bins=bins)\n",
    "        plt.legend(['untreated', 'treated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function is used in exercise 1.05 in order to compare the statistics of both groups (treated and untreated). \n",
    "\n",
    "Even though the mean is not the best element we have to describe the interval features of a whole group, it is still useful to make sure both groups are similar enough for the matching to have a real meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups(table) :\n",
    "    \"\"\"\n",
    "    Compares groups in merged dataframe\n",
    "    table : dataframe to compare treated and untreated in\n",
    "    \"\"\"\n",
    "    columns = ['untreated', 'treated']\n",
    "    index = ['age', 'educ', 'black', 'hisp', 'married', 'no_degree']\n",
    "    result = pd.DataFrame(columns=columns, index=index)\n",
    "    result['untreated']['age'] = table['age_y'].mean()\n",
    "    result['untreated']['educ'] = table['educ_y'].mean()\n",
    "    result['untreated']['black'] = table['black_y'].mean()\n",
    "    result['untreated']['hisp'] = table['hispan_y'].mean()\n",
    "    result['untreated']['married'] = table['married_y'].mean()\n",
    "    result['untreated']['no_degree'] = table['nodegree_y'].mean()\n",
    "    result['treated']['age'] = table['age_x'].mean()\n",
    "    result['treated']['educ'] = table['educ_x'].mean()\n",
    "    result['treated']['black'] = table['black_x'].mean()\n",
    "    result['treated']['hisp'] = table['hispan_x'].mean()\n",
    "    result['treated']['married'] = table['married_x'].mean()\n",
    "    result['treated']['no_degree'] = table['nodegree_x'].mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Propensity Score Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this exercise is to analyze a dataset first without any real knowledge (naive analysis) and then through multiple processing steps to understand the data further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the data (and displaying it to understand the format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lalonde_df = pd.read_csv('lalonde.csv')\n",
    "lalonde_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data, we can easily imagine that the first thing we need to do is split the salary data (_['re78']_) into 2 sets: treated and untreated. This will be useful throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks to be used\n",
    "treated = (lambda x: x.treat == 1)\n",
    "untreated = (lambda x: x.treat == 0)\n",
    "\n",
    "#mask application to the first DF\n",
    "treated_salary = lalonde_df[treated(lalonde_df)]['re78']\n",
    "untreated_salary = lalonde_df[untreated(lalonde_df)]['re78'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that a naive researcher unfamiliar with observational studies would treat the data as a randomized trial, not taking into consideration the hidden correlates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Describing the numbers**\n",
    "\n",
    "We first look at the numbers to see how many subjects we have in each group and to see how the values are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lalonde_df.groupby('treat')['re78'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First insights:\n",
    "\n",
    "- The untreated group has more people and their salaries have a higher mean.\n",
    "- However, the 1st salary quartile is twice higher in the treated group and the maximum salary is 3x higher!\n",
    "- We have that the 2nd and 3rd quartiles are higher in the untreated group. Quartiles are more resistent to outliers, hence indicating that the control group is faring better.\n",
    "- Finally, the interquartile distance is larger in the untreated set (because of outliers). We use this measure because it is better to measure _'variance'_. Thus, we can say that the control group has a more heterogenous salary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Visualizing the data:**\n",
    "\n",
    "We now plot the _['re78']_ salary data in a histogram (with equal sized bins) to find the distribution of salaries of the two groups. We add weights to be able to look at percentages instead of at the number of people in both groups (not equal, meaning it is not informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "bins = np.linspace(0, max(lalonde_df['re78']), 50)\n",
    "plt.hist(untreated_salary, weights=np.ones(len(untreated_salary))/len(untreated_salary), alpha=.5 , bins=bins)\n",
    "plt.hist(treated_salary, weights=np.ones(len(treated_salary))/len(treated_salary), alpha=.5, bins=bins)\n",
    "plt.title('Histogram showing salary treated and untreated groups')\n",
    "plt.legend(['untreated', 'treated'])\n",
    "plt.xlabel('Yearly salary')\n",
    "plt.ylabel('percentage of subjects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second insights:\n",
    "\n",
    "We see a very similar distribution for both functions in the graph, except for the outliers present in the treated group. We also note that there are relatively more subjects in the untreated group with a salary between 10K and 20K while both groups have a similar ratio of subjects in the <10K section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Boxplot:**\n",
    "\n",
    "We use boxplots to illustrate the above number more concisely using a 5 number summary. Note that we remove outliers as we do not consider them to be representative of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_treat_untreat(treated_salary, untreated_salary):\n",
    "    \"\"\"draws boxplot of distribution of salary \"\"\"\n",
    "    plt.boxplot([treated_salary, untreated_salary], labels=['treated', 'untreated'], showfliers=False)\n",
    "    plt.title('Distribution of salary by treated and untreated')\n",
    "    plt.ylabel('Salary')\n",
    "    plt.show()\n",
    "\n",
    "boxplot_treat_untreat(treated_salary, untreated_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "\n",
    "If the treatment was effective, we should have noticed that the people in the treated group were more sucessful on average as they were placed in program (whereas for the untreated group, they were left to fend for themselves).\n",
    "\n",
    "By merging the insights of his 3 steps analysis, the researcher can conclude that **the treatment shows no effect**. The salary distributions are similar in both groups, indicating that the treatment isn't effective.\n",
    "\n",
    "Additionally, the treated group has a lower salary in average (except for the handful of lucky people who find a good job) which is shown by the boxplot: the whiskers extend higher in the untreated group and the median and lower wisker are situated higher up. Since the difference is somewhat small, this may just be due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A closer look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing a simplistic analysis of the data where we ignored underlying factors (such as race and education) that could influence the outcome, we start looking at the whole table assuming that the other features have an impact on _['re78']_.\n",
    "\n",
    "Note that we split our analysis into **categorical** and **interval** data (before determining the correlation between all variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i - Categorical data :**\n",
    "\n",
    "We can study the categorical data (race, degree and mariage) using their percentages in each population (as the treated and untreated groups have different sizes). To do this, we will simply use the mean of the values because averaging 0s and 1s gives us the percentage of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['black', 'hispan', 'married', 'nodegree']\n",
    "percentages = lalonde_df.groupby('treat')[categories].mean()\n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Race ratios:\n",
    "\n",
    "We will start with race. As we do not have numbers for white participants, we substract the number of black and hispanic participants from the total of each treatment. This is possible because there is no overlap between the _['black']_ and _['hispan']_ categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_u, black_t = percentages['black']\n",
    "hispan_u, hispan_t = percentages['hispan']\n",
    "white_u, white_t = (1 - black_u - hispan_u, 1 - black_t - hispan_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_race_rates = [black_u, hispan_u, white_u]\n",
    "t_race_rates = [black_t, hispan_t, white_t]\n",
    "race_labels = 'Black', 'Hispanic', 'White'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_race_rates, t_race_rates, race_labels, 'Racial groups in percent by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are significantly more black subjects in the treated group than in the untreated group. We also note that there are more hispanics in the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Degree ratios:\n",
    "\n",
    "To have a better understanding of the difference of salaries, we also need to look at the level of education of  participants in each treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_u, degree_t = percentages['nodegree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_degree_rates = [degree_u, 1 - degree_u]\n",
    "t_degree_rates = [degree_t, 1 - degree_t]\n",
    "degree_labels = 'Degree', 'No degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_degree_rates, t_degree_rates, degree_labels, 'Percentage of individuals with a degree, by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the population of treated group is less educated (there is over 10% more people with no degree in the treated set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Marriage ratios:\n",
    "Finally, we analyze our last feature: the rate of married people among both groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "married_u, married_t = percentages['married']\n",
    "not_married_u, not_married_t = (1 - married_u, 1 - married_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_marriage_rates = [married_u, not_married_u]\n",
    "t_marriage_rates = [married_t, not_married_t]\n",
    "mariage_labels = ['Married', 'Not married']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPies(u_marriage_rates, t_marriage_rates, mariage_labels, 'Percentage of married individuals by treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note once again less married people in the treated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Unemployment ratios:\n",
    "\n",
    "Even though salaries are not categories but intervals, it is important to compare unemployment rates between both groups (which we define as categories: _employed_ and _unemployed_). To get better insights, we plot the evolution of this rate through the years by displaying _['re74']_ and _['re75']_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = ['re74', 're75']\n",
    "cat_salaries = lalonde_df.copy()\n",
    "unemployed_labels = 'Employed', 'Unemployed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We draw a boxplot for each column\n",
    "for sal in salaries:\n",
    "    #We classify the data following : employed = 1 and unemployed = 0\n",
    "    cat_salaries[sal] = cat_salaries[sal].map(lambda x : 0 if x == 0 else 1)\n",
    "    u_employed, t_employed = cat_salaries.groupby('treat')[sal].mean()\n",
    "    drawPies([1-u_employed, u_employed],[1-t_employed, t_employed], \n",
    "             unemployed_labels, 'Unemployment rates by treatment in 19'+sal[-2:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the assumption that both groups are balanced before treatment is also wrong for unemployment as we find much more unemployed people in the treated group than in the untreated group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the categorical data, we find that the underlying factors are not similar at all among both groups (the treated group is significantly more black, less educated, less employed and less married). All these factors influence employment and should be taken into consideration.\n",
    "\n",
    "These factors influence salary in the following ways:\n",
    "- Due to racial inequality (especially given the period, the _1970s_), non-white people are more likely to work in worse paying jobs and/or be underpayed.\n",
    "- Better education gets better jobs.\n",
    "- People who already had jobs in 1974/5 are more likely to still have a job in 1978 (and may even have had a raise).\n",
    "- Marriage is an indicator of stability, which may influence job prospects. People often get married when they have a stable job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii - Interval data :**\n",
    "\n",
    "We now turn to non binary data and the their distribution to get more insights on the data. To do this, we first draw a boxplot and a relative fequency histogram for all variables.\n",
    "\n",
    "_Note that we remove outliers from the box plot as we care more about the general distibution of values in the set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "intervals = ['age', 'educ', 're74', 're75']\n",
    "interval_plots(lalonde_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we see that:\n",
    "- Salaries are very unbalanced between the groups: the treatment group earns much less than the untreated group.\n",
    "- The age distribution is different as the treated group is a bit younger (a lot of individuals are in their _20s_).\n",
    "- Overall, the education level is similar. However, there are more well-educated people in the untreated group; we also note that the number of years of education does not indicate the acquirement of a degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Evolution:\n",
    "\n",
    "Even though it is useful to plot the salaries through the years, it is much more useful to understand how the salary of each participant changes. It is especially interesting to see how the outliers in each year are connected. To do so, we visualize our data using a parallel plot (**orange** represents the treated group while **blue** represents the untreated group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "parallel_coordinates(lalonde_df[untreated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Blue', alpha=0.5)\n",
    "parplot = parallel_coordinates(lalonde_df[treated(lalonde_df)][['id','re74', 're75', 're78']], 'id', color='Orange' , alpha=0.7)\n",
    "parplot.legend_.remove()\n",
    "plt.title('Salary over time for each participant')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Annualy Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plots, we can that:\n",
    "- The treated group started with a lower salary (the bracket of salaries up to 15K is all blue).\n",
    "- 1975 was a \"bad year\" for everybody (there is an indent in the plot).\n",
    "- The outliers are partially people who were already well payed in 1974 and partialy people who _\"made it\"_.\n",
    "- Most members of the treated group have seen there salaries go up between 1975 and 1978. We also see a slight upwards movement for the untreated group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  b. Salary and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed that categorical features influenced the salary, we try to see to what extent our hypothesis holds.\n",
    "\n",
    "**Plotting by race:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "white = (lalonde_df['black'] == 0) & (lalonde_df['hispan'] == 0)\n",
    "years = ['re74', 're75', 're78']\n",
    "\n",
    "for year in years:\n",
    "    plt.boxplot([lalonde_df[white][year], lalonde_df[lalonde_df['black'] == 1][year],\n",
    "                 lalonde_df[lalonde_df['hispan'] == 1][year]], \n",
    "                labels=['white', 'black', 'hispanic'])\n",
    "    plt.title('salary distribution by race in 19'+year[-2:])\n",
    "    plt.ylabel('annual earnings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that :\n",
    "- There is a racial discrepancy in salary\n",
    "- The outliers are all black individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by martial status and degree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    #marriage\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title('single vs married salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='married', y=year, hue='treat')\n",
    "    plt.ylabel('salary')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks(range(2),('singe', 'married'))\n",
    "    \n",
    "    #degree\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title('degree vs nodegree salary in 19'+year[-2:])\n",
    "    sns.boxplot(data=lalonde_df, x='nodegree', y=year, hue='treat')\n",
    "    plt.xticks(range(2),('degree', 'no degree'))\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that no matter the treatment or the year, married people earn more than single people and people with degrees make more money that people with no degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting by age**\n",
    "\n",
    "\n",
    "It is well known that age influences a person's prospects at finding a job but also influence their potential salary. Thus, we map the salary by age (and treatment) for the 3 observed years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    sns.factorplot(data=lalonde_df, x='age', y=year, hue='treat',aspect=4, size=3)\n",
    "    plt.title('salary by age and treatment in 19'+year[-2:])\n",
    "    plt.yticks(np.linspace(0, 40000, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- Pre-treatment, the treated group makes less that the untreated group.\n",
    "- Post-treatment, young people in the treated group easily catch up on people from the control group.\n",
    "- The treatment seems to have an effect (in general, people in the treated group catch up, or at least find employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "By looking at the interval data, and more specificaly at the salaries of participants, we can say that the underlying feature (race, education, marital status) influence the salary. However, our two groups are not balanced which interferes with our first analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii - Data correlation:**\n",
    "\n",
    "After working on each value alone, we want to understand how each value is (linearly) linked to others looking at each pair of features. To do this, we draw as pairplot as correlation alone does not give us any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_df[['treat', 're78']+intervals], markers='+', hue='treat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot does not tell us a lot other than the fact that we do not see any linear dependence. Thus, we do not spend more time on this part of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A propensity score model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen our naive analysis was preformed based the untrue assumption of a fair distribution in both sets.\n",
    "This is not the case.\n",
    "To create a fair set to use on our observational study, we calculate the propensity score based on the underlying factors before treatment:\n",
    "\n",
    "[age, educ, hispan, black, nodegree, re74, re75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_table = lalonde_df.copy() #otherwise we modify lalonde_df when we modify prop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our target and training data:\n",
    "\n",
    "X = prop_table.iloc[:, 2:-1] #rows age to 're75'\n",
    "y = prop_table.iloc[:, 1:2] #treated or not\n",
    "y = np.ravel(y) #flatten array\n",
    "print('First elements of Y : \\n', y[0:5],'\\nFirst elements of X\\n', X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#define our model\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X, y)\n",
    "print('Accuracy of prediction: ',logistic.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example of prediction : \", logistic.predict(X[0:6]), ' reality :', y[0:6])\n",
    "print('Example of prediction in percent : \\n', logistic.predict_proba(X[0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get propensity scores, probability of \"being a subject\"\n",
    "prop_table['propensity_scores'] = pd.Series(logistic.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the propensity scores to find a matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balancing the dataset via matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try finding a matching based on the propensity scores to get a more balanced set.\n",
    "\n",
    "Matching the two is an equivalent problem to find a matching in a bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "B = nx.Graph()\n",
    "#1. Creat graph with nodes as id\n",
    "B.add_nodes_from(prop_table['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Add edges from each treated to each untreated subject\n",
    "#    with weight on each node being the difference between the two\n",
    "for row_i in prop_table[treated(prop_table)].iterrows():\n",
    "    for row_j in prop_table[untreated(prop_table)].iterrows():\n",
    "        B.add_edge(row_i[1]['id'],row_j[1]['id'], \n",
    "                   #-x to transform minimisation problem into maximisation problem\n",
    "                   weight= 1 - np.abs(row_i[1].propensity_scores - row_j[1].propensity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Find matching\n",
    "matching_dict = nx.max_weight_matching(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example matches:')\n",
    "list(matching_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get matching\n",
    "matched = prop_table.copy()[prop_table['id'].isin(matching_dict)]\n",
    "print('we have : ',len(matched)/2, ' matched subjects') #pairs appear in 2 order s ab and ba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at the outcome\n",
    "We compare the outcome [re78] for treated and untreated groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(data=matched, x='treat', y='re78')\n",
    "plt.xticks(range(2), ('control', 'treatment'))\n",
    "plt.title('Salary in 1978')\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data=matched, x='treat', y='re78',  showfliers=False)\n",
    "plt.xticks(range(2), ('control', 'treatment'))\n",
    "plt.title('Salary in 1978, no outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the treatment group's salary distribution in 1978 is slightly higher than the control groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the feature distrbution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preforme a similary analysis to the one done in 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_percentages = matched.groupby('treat')[categoriescategorical].mean() #unbalanced\n",
    "matched_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately see that for the categorical varibles, marriage and degree rates are more balanced, while the racial distribution in the two groups is still very skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also look at interval data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_plots(matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that they are all much more balanced than before, especially educ and re75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Balancing the groups further\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your comparison of feature-value distributions from part 4, are you fully satisfied with your matching?\n",
    "Would you say your dataset is sufficiently balanced?\n",
    "If not, in what ways could the \"balanced\" dataset you have obtained still not allow you to draw valid conclusions?\n",
    "\n",
    "Improve your matching by explicitly making sure that you match only subjects that have the same value for the problematic feature.\n",
    "Argue with numbers and plots that the two groups (treated and control) are now better balanced than after part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted above there are still way more black subjects in the treated group than in the untreated group.\n",
    "Additionaly, we still have outliers in the treated group.\n",
    "\n",
    "We try to balance the both groups by removing white subjects matched with black subjects.\n",
    "We als balance the distribution of teh hispanic subjects in both groups\n",
    "We first merge the two dataframes to have the matched subjects side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergin dataframe and adding propensity score difference column .. do we still need this?\n",
    "matched['match'] = matched['id'].map(matching_dict)\n",
    "balanced_match = matched[treated(matched)].merge(matched[untreated(matched)], left_on='id', right_on='match')\n",
    "balanced_match['difference'] = abs(balanced_match['propensity_scores_x'] - balanced_match['propensity_scores_y'])\n",
    "print('we have : ', len(balanced_match), ' matched subjects')\n",
    "balanced_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the matched pairs that are white/black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches that are black/white hispanic/white missmatched\n",
    "race_bool_1 = (balanced_match['black_x'] == 1) & (balanced_match['black_y'] == 0)\n",
    "#this removes black hispanic pairs??? is this what you want??? it actuay doesn't change anything at all anyway\n",
    "#tell me why...\n",
    "#race_bool_2 = (balanced_match['black_x'] == 1) & (balanced_match['hispan_y'] == 1)\n",
    "#other syntax didn't work\n",
    "balanced_match = balanced_match.drop(balanced_match[race_bool_1].index)\n",
    "#balanced_match = balanced_match.drop(balanced_match[race_bool_2].index)\n",
    "print('we have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if the data set is more balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)\n",
    "#but now married is mismatched smh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_blanced_interval(df):\n",
    "    df1 = df.iloc[:,:11]\n",
    "    df2 = df.iloc[:, 13:-3]\n",
    "    df2.columns = lalonde_df.columns\n",
    "    df1.columns = lalonde_df.columns\n",
    "    balanced_df = pd.concat([df1, df2])\n",
    "    interval_plots(balanced_df)\n",
    "    \n",
    "plot_blanced_interval(balanced_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches that are black/white missmatched and have a large difference in propensity scores\n",
    "marriage_bool_1 = (balanced_match['married_x'] == 1) & (balanced_match['married_y'] == 0)\n",
    "marriage_bool_2 = (balanced_match['married_y'] == 1) & (balanced_match['married_x'] == 0)\n",
    "balanced_match = balanced_match.drop(balanced_match[marriage_bool_1 | marriage_bool_2].index)\n",
    "print('we have : ', len(balanced_match), ' matched subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The match seems balanced blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at interval data and see blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_blanced_interval(balanced_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finaly we remove outliers from the lucky few from the treatment set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers - no need unless looking at mean\n",
    "balanced_match = balanced_match.drop(balanced_match[balanced_match.re78_x > 30000].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the outcomes (`re78`) between treated and control subjects, as you've done in part 1, but now only for the matched dataset you've obtained from part 5.\n",
    "What do you conclude about the effectiveness of the job training program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_treat_untreat(balanced_match['re78_x'], balanced_match['re78_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat([balanced_match.re78_y.describe(),balanced_match.re78_x.describe()], axis=1)\n",
    "stats.columns = ['untreated', 'treated']\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After controlling for unerlying factors we see that the treated population fares better than the untreated population, which we can see as the overall distribution of the salary in the two groups is moved up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Applied ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we build a text classifier and analyze it's preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transforming the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to compute the TF-IDF features of our dataset, using a vectorizer. As we understood the question, it was not asked to use any of the given datasets from sklearn, but to use all of the data. Thus, we do not use the train and test subsets given to us in sklearn, but will create our own such subsets, adding a validation subset.\n",
    "\n",
    "Also note that we **remove the headers, footers and quotes**, as proposed in the <a href=\"http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\">sklearn tutorial</a> of the dataset, as to have something more realistic and without any of the metadata. \n",
    "This significantly decreases our accuracy, as we show later in section 3.\n",
    "\n",
    "Note also that we did not use the *sklearn.datasets.fetch_20newsgroups_vectorized* function that returns the TF-IDF features directly, as it would defeat the purpose of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data we need to use the vectorizer on. Remove metadata as proposed by sci-kit tutorial\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_with_header = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As asked in the question, before seperating in subsets, we will use the vectorizer on the complete set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors is a sparse matrix\n",
    "X = tfidf.fit_transform(newsgroups_all.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to seperate the dataset into three sets: train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we seperate train from the rest. Random_state given to have a seed.\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_all.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "# then we seperate again to get validation and test seperately\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the classifier\n",
    "\n",
    "Now we need to train a random forest on our training set. For this, we will use the RandomForestClassifier, as it contains the parameters talked about in the exercise. But first, we need to ask ourselves what we want to set the parameters (*max_depth* and *n_estimators*) to.\n",
    "\n",
    "We set the two parameters to get a first idea on what values we will get for the prediction.\n",
    "We use 100 trees and a depth of 25, values that are similar to the ones given in the course.\n",
    "\n",
    "For the predictions, we can't use the training set, as we just trained on it and thus would get very good results regardless of the goodness of fit. So prediction has to be on the validation set.\n",
    "\n",
    "We use two measure the goodness of our system to the data by two measures, F1 score and prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find estimators and depth first.\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=25)\n",
    "clf.fit(vect_train, newsgroups_train)\n",
    "pred = clf.predict(vect_valid)\n",
    "metrics.f1_score(newsgroups_valid, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ',metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, predictions aren't that great.\n",
    "\n",
    "We try to fine tune on the validation set. We first used skikit's GridSearchCV function, but could not find the right parameters to make the function work perfectly. \n",
    "In fact, the best parameters were almost always the highest ones, yet the results of predictions stayed quite poor.\n",
    "\n",
    "Thus, we decided to use a double for loop, implementing the grid search. Even if this type of computation is very heavy and takes a lot more time aswell.\n",
    "\n",
    "Please note that finding a good fit over a large range of values takes a lot of time to compute, as there are a very large numbers of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We made a few tries already to determine which values yield better results.\n",
    "# We have a double for loop. Which is aweful and will take a lot of time, but necessary.\n",
    "def GridSearch(X_train, y_train, X_valid, y_valid, range_estimator, range_depth):\n",
    "    \"\"\"Implements grid search, goes over range_estimator and range_depth, returns best parameter in the ranges\n",
    "    X_train: set to train on\n",
    "    y_train: true values training\n",
    "    X_valid: set to test on\n",
    "    y_valid: true values for testing\n",
    "    range_estimator: range to go over for estimator\n",
    "    range_depth: range to go over for depth\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i in range_estimator: #making sure the depth is not better above 30\n",
    "        for j in range_depth: #step of 100 to not take too much time\n",
    "            clf = RandomForestClassifier(n_estimators=j, max_depth=i, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_valid)\n",
    "            pred_result = metrics.accuracy_score(y_valid, pred)\n",
    "            # uncomment next line to be able to know where computation is at\n",
    "            print(i,\" ; \", j)\n",
    "            rows.append([i, j, pred_result])\n",
    "    # We create a DF to be able to use all this data effectively\n",
    "    columns=['Depth', 'Estimators', 'Prediction']\n",
    "    all_predictions = pd.DataFrame(rows, columns=columns) # we get all the predictions in a dataframe\n",
    "    # we sort by best prediction\n",
    "    all_predictions = all_predictions.sort_values(by=['Prediction'], ascending=False)\n",
    "    # we show the best 10\n",
    "    return all_predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_predictions = GridSearch(X_train, y_train, X_valid, y_valid, range(30, 160, 30), range(300, 1100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously run the loop overnight and saved the findings into a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the pickle. Do not run if we did not make a new pandas.\n",
    "# all_predictions.to_pickle(\"all_predictions.pkl\")\n",
    "# read the pickle.\n",
    "all_predictions = pd.read_pickle(\"all_predictions.pkl\")\n",
    "all_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly visualize the points in the file to get an overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.suptitle('Depth, Estimator and precision accuracy')\n",
    "plt.subplot(2,2,1)\n",
    "plt.ylabel('precision accuracy')\n",
    "plt.scatter(all_predictions['Depth'], all_predictions['Prediction'])\n",
    "plt.xlabel('depth')\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "plt.xlabel('number of estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(all_predictions['Depth'], all_predictions['Estimators'], all_predictions['Prediction'])\n",
    "ax.set_title('3d plot of estimators depth and precision relationship')\n",
    "ax.set_xlabel('depth')\n",
    "ax.set_ylabel('number of estimators')\n",
    "ax.set_zlabel('prediction accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, te best resuts are when *n_estimators* is set around 700 and *max_depth* is set at 130. Note that because we have a bit of randomness, the results are not deterministic.\n",
    "\n",
    "We note that tutorials on the internet show 80% and more accuracy for random forest classifiers, where as we only get 68%.\n",
    "This is because we have taken out all metadata, as asked for by the tutorial on sklearn. Thus, we have more realistic predictions and results. To show this, let us compare predictions with and without metadata in section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a confusion matrix on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "#get confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "#renaming for convenience\n",
    "df.columns = newsgroups_all.target_names\n",
    "df.index = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to read this matrix, lets put it into a DataFrame and add the right column names, then show the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal shows us the true positives. we see that some classes have higher prediction accuracy than others.\n",
    "Our classifier classifies sport.hockey very well but has great trouble classifying talk.religious.misc correctly.\n",
    "\n",
    "Then the mixups (false negatives & false positives) are within similar topics, such as religion.muisc & religion.christian –this is a false negative, the classifier assigned talk.religion.misc but the true lable is talk.religion.misc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the `feature_importances_` attribute of our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most significant features\n",
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not suprising to see keywords such as car or god in this list, as they clearly indicate a topic. A text containing god will more likely be religous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst still positive \n",
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the least indicative still indicative features are very cryptic, they probably only show up in one text, but strongly indicate the type of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at te most relevant features in relation to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature impotance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the first are very relevant, and the the slope of relevancy slowly goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also have an idea of how many features are important or not by plotting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "#note the log scale!\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that very few features are very important, while most are useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prediction with lables\n",
    "\n",
    "We now show how much better the prediction is if we keep the lables in the dataset.\n",
    "\n",
    "We prefrom the same data processing as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors is a sparse matrix\n",
    "X = tfidf.fit_transform(newsgroups_with_header.data)\n",
    "\n",
    "# first we seperate train from the rest. Random_state given to have a seed.\n",
    "y_train, y_inter, X_train, X_inter = \\\n",
    "    train_test_split(newsgroups_with_header.target, X, test_size=0.2, random_state=1)\n",
    "\n",
    "# then we seperate again to get validation and test seperately\n",
    "y_test, y_valid, X_test, X_valid = \\\n",
    "    train_test_split(y_inter, X_inter, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the assumption that the estimators on both sets will be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=700, max_depth=130, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('F1 score for basic parameters : ', metrics.f1_score(y_valid, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for basic parameters : ', metrics.accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immeditely see that the results are much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "#get confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, pred_test)\n",
    "df = pd.DataFrame(cm)\n",
    "#renaming for convenience\n",
    "df.columns = newsgroups_all.target_names\n",
    "df.index = newsgroups_all.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to read this matrix, lets put it into a DataFrame and add the right column names, then show the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Confusion matrix')\n",
    "sns.heatmap(df, cmap='OrRd', annot=True, cbar=False)\n",
    "plt.ylabel('predicted label')\n",
    "plt.xlabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that compared to the previous confusion matrix we have a lot more true positives and less false negatives & false positives.\n",
    "\n",
    "The features that were hard to label before still get labeled incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the `feature_importances_` attribute of our random forest for this classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most significant features\n",
    "features = pd.DataFrame(list(zip(tfidf.get_feature_names(), clf.feature_importances_)))\n",
    "features = features.sort_values(by=[1], ascending=False)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst still positive \n",
    "features = features.sort_values(by=[1], ascending=True)\n",
    "features[features[1] > 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the unsignificant features are more nonsensical than before and the significant features stay similar, although there is some change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at te most relevant features in relation to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(range(0, 200),feature_importance.head(200))\n",
    "plt.title('feature impotance for most relevant features')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the first are very relevant, and the the slope of relevancy is a lot more steep than in the above case.\n",
    "We thus have a very few very relevant features, an less lesser relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also have an idea of how many features are important or not by plotting them in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clf.feature_importances_, bins=50)\n",
    "#note the og scale!\n",
    "plt.yscale('log')\n",
    "plt.title(' histogram for feature importance')\n",
    "plt.xlabel('importance by feature')\n",
    "plt.ylabel('Number of features (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the feature importance distributon does not change a lot by adding metadata to the set.\n",
    "Unsignificant and significant features are however more separated compared to the features obtained before and the distribution is sightly shifted to the left."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
