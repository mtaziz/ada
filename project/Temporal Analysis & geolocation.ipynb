{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_distribution(times):\n",
    "    publishing_time = times.map(lambda x: x.hour).value_counts() / times.count()\n",
    "    publishing_time.sort_index(inplace=True)\n",
    "    return publishing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily(depressed):\n",
    "    neg = get_time_distribution(depressed[depressed.sentiment == 'NEGATIVE']['published'])\n",
    "    neut = get_time_distribution(depressed[depressed.sentiment == 'NEUTRAL']['published'])\n",
    "    pos = get_time_distribution(depressed[depressed.sentiment == 'POSITIVE']['published'])\n",
    "\n",
    "    plt.plot(neg)\n",
    "    plt.plot(neut)\n",
    "    plt.plot(pos)\n",
    "    plt.legend(['negative', 'neutral', 'positive'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I look at the different temporal distribution.\n",
    "First look at emotion over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load( open( \"keyword_frames/english_keyworded_tweets.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english = df[(~df['keywords'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english[english.keywords.map(lambda x: len(x) > 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad = english[english.keywords.map(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_time_distribution(sad.published).plot()\n",
    "get_time_distribution(english.published).plot()#not usefull \n",
    "plt.legend(['sad', 'general'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sad_people = sad.author_gender.value_counts() / sad.author_gender.count()\n",
    "sad_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people = english.author_gender.value_counts()/ english.author_gender.count()\n",
    "all_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people.iloc[1:].plot(kind='bar')\n",
    "plt.figure()\n",
    "sad_people.iloc[1:].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_s = sad.sentiment.value_counts() / sad.sentiment.count()\n",
    "sentiment_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_yearly(times):\n",
    "    publishing_time = times.map(lambda x: x.month).value_counts() / times.count()\n",
    "#     publishing_time.sort_index(inplace=True)\n",
    "    return publishing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_y = get_yearly(df.published)\n",
    "neg_y = get_yearly(df[df.sentiment == 'NEGATIVE']['published'])\n",
    "neut_y = get_yearly(df[df.sentiment == 'NEUTRAL']['published'])\n",
    "pos_y = get_yearly(df[df.sentiment == 'POSITIVE']['published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the way spinner collected the tweets indicated that there is a difference in the frequency od tweets\n",
    "sns.tsplot(data=neg_y, color='Purples')\n",
    "sns.tsplot(data=pos_y, color='Reds')\n",
    "sns.tsplot(data=neut_y)\n",
    "plt.legend(['negative', 'positive', 'neutral'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the f are we supposed to deal with such an unequally distribued dataset????\n",
    "-> we do this by working on the big dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.author_user_id.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.geo_point.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source_location.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_location_data(df):\n",
    "    \"\"\"preprocessed data in format as found on cluster:\n",
    "    df: dataframe, locations should be in 'geo_point'\n",
    "    \"\"\"\n",
    "    non_null = df[~df.geo_point.isnull()]\n",
    "    virgule = non_null[non_null.geo_point.str.contains(',')].geo_point.str.split(pat=',', expand=True).applymap(float)\n",
    "    no_virgule = non_null[~non_null.geo_point.str.contains(',')].geo_point.str.split(expand=True).applymap(float)\n",
    "    return pd.concat([virgule, no_virgule])\n",
    "    \n",
    "\n",
    "\n",
    "def build_map(location):\n",
    "    \"\"\"build swiss location map\n",
    "    location: dataframe, locations must of type [lat, long]'\n",
    "    note: location should not contain more than 5000 locations, otherwise buggy\n",
    "    \"\"\"\n",
    "    SWISS_COORD = [46.85, 8.23] #location of switzerland\n",
    "    swiss_map = folium.Map(location = SWISS_COORD, zoom_start = 8, tiles = 'cartodbpositron')\n",
    "    marker_cluster = MarkerCluster().add_to(swiss_map)\n",
    "    for each in location.iterrows():\n",
    "        folium.Marker([each[1][0],each[1][1]], ).add_to(marker_cluster)\n",
    "    return swiss_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = process_location_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swiss_map = build_map(location=locations.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "swiss_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_points = df.geo_point.value_counts().reset_index()\n",
    "aggregated_points.columns = ['geo_point', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = process_location_data(aggregated_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_map = build_map(location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_map"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
